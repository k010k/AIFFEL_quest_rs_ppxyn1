{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e1fa94",
   "metadata": {},
   "source": [
    "# 21-1.mini BERT 만들기\n",
    "vocab size를 8000으로 줄이고, 전체 파라미터 사이즈가 1M 정도가 되는 아주 작은 mini BERT 모델을 만들어 10 Epoch까지 학습시킨 모델을 만들어 보는 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35f699c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sentencepiece as spm\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b59e27",
   "metadata": {},
   "source": [
    "# 1. Tokenizer 준비\n",
    "SentencePiece 모델을 이용해 BERT의 MLM 학습용 데이터를 만드세요.  \n",
    "이를 위해 한글 나무 위키 코퍼스로부터 8000의 vocab_size를 갖는 sentencepiece 모델을 만들어 보세요. BERT에 사용되는 주요 특수문자가 vocab에 포함되어야 합니다. (시간이 부족하다면 클라우드에 저장된 sentencepiece 모델을 사용하세요.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b43ffe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( os.getenv('HOME')) +'/aiffel/assets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cb1af60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/data'\n",
    "model_dir = os.getenv('HOME')+'/data'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_8000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71d76417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 8007\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size:\", vocab.get_piece_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb5cb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Q. 특수 token 7개를 제외한 나머지 token들을 출력해봅시다.\n",
    "# vocab_list = []\n",
    "# for id in range(7, len(vocab)):\n",
    "#         if not vocab.is_unknown(id):\n",
    "#             vocab_list.append(vocab.id_to_piece(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a0af0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe250a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [CLS], tokens a, [SEP], tokens b, [SEP] 형태의 token 생성\n",
    "# string_a = \"추적추적 비가 내리는 날이었어 그날은 왠지 손님이 많아 첫 번에 삼십 전 둘째번 오십 전 오랜만에 받아보는 십 전짜리 백통화 서푼에\"\n",
    "# string_b = \"손바닥 위엔 기쁨의 눈물이 흘러 컬컬한 목에 모주 한잔을 적셔 몇 달 포 전부터 콜록거리는 아내 생각에 그토록 먹고 싶다던\"\n",
    "# tokens_org = [\"[CLS]\"] + vocab.encode_as_pieces(string_a) + [\"[SEP]\"] + vocab.encode_as_pieces(string_b) + [\"[SEP]\"]\n",
    "# print(tokens_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6e1b98",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리 (1) MASK 생성   \n",
    "BERT의 MLM에 필요한 빈칸(mask)을 학습 데이터 전체 토큰의 15% 정도로 만들어 주세요. 그 중 80%는 [MASK] 토큰, 10%는 랜덤한 토큰, 나머지 10%는 원래의 토큰을 그대로 사용하세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5990cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokens_org)\n",
    "# print(tokens_org[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d9e1381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 token의 15% mask\n",
    "mask_cnt = int((len(tokens_org) - 3) * 0.15)\n",
    "mask_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e543c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Masked LM 태스크를 구성할 땐 띄어쓰기 단위로 한꺼번에 마스킹해 주는 것이 좋습니다.\n",
    "# cand_idx = []  # word 단위의 index array\n",
    "# for (i, token) in enumerate(tokens_org):\n",
    "#     if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "#         continue\n",
    "        \n",
    "#     #TODO: ?\n",
    "#     if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  # u\"\\u2581\"는 단어의 시작을 의미하는 값\n",
    "#         cand_idx[-1].append(i)\n",
    "#     else:\n",
    "#         cand_idx.append([i])\n",
    "\n",
    "# for cand in cand_idx:\n",
    "#     print(cand, [tokens_org[i] for i in cand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f2072c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # random mask를 위해서 index 순서를 섞음\n",
    "# random.shuffle(cand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30a060c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "# tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "# mask_lms = []  # mask 된 값\n",
    "# for index_set in cand_idx:\n",
    "#     if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "#           break\n",
    "#     if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "#           continue\n",
    "#     dice = random.random()  # 0과 1 사이의 확률 값\n",
    "\n",
    "#     for index in index_set:\n",
    "#         masked_token = None\n",
    "#         if dice < 0.8:  # 80% replace with [MASK]\n",
    "#             masked_token = \"[MASK]\"\n",
    "#         elif dice < 0.9: # 10% keep original\n",
    "#             masked_token = tokens[index]\n",
    "#         else:  # 10% random word\n",
    "#             masked_token = random.choice(vocab_list)\n",
    "#         mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "#         tokens[index] = masked_token\n",
    "\n",
    "# print(\"tokens_org\")\n",
    "# print(tokens_org, \"\\n\")\n",
    "# print(\"tokens\")\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d2e37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(mask_lms))\n",
    "\n",
    "# print(mask_lms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71a9ae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Masked LM의 라벨 데이터도 아래와 같이 생성하여 정리해 둡니다.\n",
    "# # 순서 정렬 및 mask_idx, mask_label 생성\n",
    "# mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "# mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "# mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "# print(\"mask_idx   :\", mask_idx)\n",
    "# print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "effe8f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokens가 mask되므로 재 실행을 위해서 넣어줌 (테스트용)\n",
    "# tokens = copy.deepcopy(tokens_org)\n",
    "\n",
    "# tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)\n",
    "\n",
    "# print(\"tokens_org\")\n",
    "# print(tokens_org, \"\\n\")\n",
    "# print(\"tokens\")\n",
    "# print(tokens, \"\\n\")\n",
    "\n",
    "# print(\"mask_idx   :\", mask_idx)\n",
    "# print(\"mask_label :\", mask_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887e051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked LM을 위한 코퍼스 생성 메소드\n",
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할 (띄어쓰기)\n",
    "    cand_idx = []\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token not in [\"[CLS]\", \"[SEP]\"]:\n",
    "            cand_idx.append(i)\n",
    "\n",
    "\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    mask_lms = []\n",
    "    for i in cand_idx[:mask_cnt]:  # mask_cnt만큼만 마스크\n",
    "        dice = random.random()\n",
    "        original_token = tokens[i]\n",
    "\n",
    "        if dice < 0.8:  # 80%는 [MASK]\n",
    "            tokens[i] = \"[MASK]\"\n",
    "        elif dice < 0.9:  # 10%는 원본 그대로\n",
    "            tokens[i] = original_token\n",
    "        else:  # 10%는 랜덤한 다른 토큰\n",
    "            tokens[i] = random.choice(vocab_list)\n",
    "\n",
    "        mask_lms.append({\"index\": i, \"label\": original_token})\n",
    "\n",
    "\n",
    "\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출 (sorted 사용)\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75eabe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = copy.deepcopy(tokens_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ac5aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, mask_idx, mask_label = create_pretrain_mask(tokens, mask_cnt, vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c64ec8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 14 14\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens),len(mask_idx),len(mask_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6656e",
   "metadata": {},
   "source": [
    "# 3. 데이터 전처리 (2) NSP pair 생성\n",
    "- BERT의 pretrain task인 NSP는 두 문장이 연속하는지 확인하는 것입니다. 이를 위해 2개의 문장을 짝지어 50%의 확률로 TRUE와 FALSE를 지정해 주세요.  \n",
    "- 두 문장 사이에 segment 처리를 해주세요. 첫 번째 문장의 segment는 0, 두 번째 문장은 1로 채워준 후 둘 사이에 구분자인 [SEP] 등을 넣어주세요.  \n",
    "- MLM과 NSP는 동시에 학습된다는 것을 염두에 두고 학습 데이터를 구성해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c23d0a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이\n",
    "n_test_seq = 64\n",
    "# 최소 길이\n",
    "min_seq = 8\n",
    "# [CLS], tokens_a, [SEB], tokens_b, [SEP]\n",
    "max_seq = n_test_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5359659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    max_seq = n_seq - 3\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])\n",
    "        current_length += len(doc[i])\n",
    "\n",
    "        if len(current_chunk) > 1 and (i == len(doc) - 1 or current_length >= max_seq):\n",
    "            # a_end를 정하는 부분\n",
    "            a_end = random.randrange(1, len(current_chunk)) if len(current_chunk) > 1 else 1\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            # is_next 결정 (50% 확률로 swap)\n",
    "            if random.random() < 0.5:\n",
    "                is_next = 0  # 다른 문장\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1  # 동일 문장\n",
    "\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "\n",
    "            # tokens & segment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * mask_prob), vocab_list)\n",
    "\n",
    "            # instance 생성\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,  \n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "\n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f568a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9d44054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3957761\n"
     ]
    }
   ],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7831f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 105/3957761 [00:00<09:18, 7080.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 lines : ['▁지', '미', '▁카', '터']\n",
      "['▁제임스', '▁얼', '▁\"', '지', '미', '\"', '▁카', '터', '▁주', '니어', '(,', '▁192', '4', '년', '▁10', '월', '▁1', '일', '▁~', '▁)', '는', '▁민주', '당', '▁출신', '▁미국', '▁3', '9', '번째', '▁대통령', '▁(19', '7', '7', '년', '▁~', '▁1981', '년', ')', '이다', '.']\n",
      "['▁그는', '▁2002', '년', '▁말', '▁인', '권', '과', '▁중', '재', '▁역할', '에', '▁대한', '▁공', '로를', '▁인정', '받아', '▁노', '벨', '▁평화', '상을', '▁받', '게', '▁되었다', '.']\n",
      "\n",
      "14 lines : ['▁수학']\n",
      "['▁수학', '(', '數', '學', ',', '▁)', '은', '▁양', ',', '▁구조', ',', '▁공간', ',', '▁변화', ',', '▁미', '적', '분', '▁등의', '▁개념', '을', '▁다루', '는', '▁학', '문', '이다', '.', '▁현대', '▁수학', '은', '▁형식', '▁논', '리를', '▁이용', '해서', '▁공', '리로', '▁구성된', '▁추', '상', '적', '▁구조를', '▁연구', '하는', '▁학', '문', '으로', '▁여겨', '지', '기도', '▁한다', '.', '▁수학', '은', '▁그', '▁구조', '와', '▁발전', '▁과정', '에서는', '▁자연', '과학', '에', '▁속하는', '▁물리', '학을', '▁비롯한', '▁다른', '▁학', '문', '들과', '▁깊', '은', '▁연', '관을', '▁맺', '고', '▁있다', '.', '▁하지만', ',', '▁어느', '▁과학', '의', '▁분야', '들과', '는', '▁달리', ',', '▁자연', '계에서', '▁관측', '되지', '▁않는', '▁개념', '들에', '▁대해서', '까지', '▁이론', '을', '▁일반', '화', '▁및', '▁추', '상', '화', '시', '킬', '▁수', '▁있다는', '▁차', '이가', '▁있다고', '▁한다', '.', '▁수', '학자', '들은', '▁그러', '한', '▁개념', '들에', '▁대해서', '▁추', '측', '을', '▁하고', ',', '▁적', '절', '하게', '▁선택', '된', '▁정의', '와', '▁공', '리', '로부터', '의', '▁엄', '밀', '한', '▁연', '역을', '▁통해', '서', '▁추', '측', '들의', '▁진', '위를', '▁파', '악', '한다', '.']\n",
      "['▁수', '학의', '▁기초', '를', '▁확', '실', '히', '▁세', '우', '기', '▁위해', ',', '▁수', '리', '논', '리', '학과', '▁집합', '론', '이', '▁발전', '하였고', ',', '▁이와', '▁더불어', '▁범', '주', '론', '이', '▁최근', '에도', '▁발전', '되고', '▁있다', '.', '▁“', '근', '본', '▁위', '기', '”', '라는', '▁말', '은', '▁대', '략', '▁19', '00', '년', '에서', '▁1930', '년', '▁사이에', '▁일어난', ',', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁탐', '구를', '▁상징', '적으로', '▁보여', '주는', '▁말이다', '.', '▁수', '학의', '▁엄', '밀', '한', '▁기초', '에', '▁대한', '▁몇', '▁가지', '▁의견', '▁불', '일', '치는', '▁오늘날', '에도', '▁계속', '되고', '▁있다', '.', '▁수', '학의', '▁기초', '에', '▁대한', '▁위', '기는', '▁그', '▁당시', '▁수많은', '▁논', '쟁', '에', '▁의해', '▁촉', '발', '되었으며', ',', '▁그', '▁논', '쟁', '에는', '▁칸', '토', '어의', '▁집합', '론', '과', '▁브라', '우', '어', '-', '힐', '베', '르트', '▁논', '쟁', '이', '▁포함', '되었다', '.']\n",
      "\n",
      "4 lines : ['▁수학', '▁상', '수']\n",
      "['▁수학', '에서', '▁상', '수', '란', '▁그', '▁값', '이', '▁변', '하지', '▁않는', '▁불', '변', '량', '으로', ',', '▁변', '수의', '▁반대', '말', '이다', '.', '▁물리', '▁상', '수', '와는', '▁달리', ',', '▁수학', '▁상', '수는', '▁물리', '적', '▁측정', '과는', '▁상', '관', '없이', '▁정의', '된다', '.']\n",
      "['▁특정', '▁수학', '▁상', '수', ',', '▁예를', '▁들', '면', '▁골', '롬', '-', '딕', '맨', '▁상', '수', ',', '▁프랑', '세', '즈', '-', '로', '빈', '슨', '▁상', '수', ',', '▁formula', '_1', ',', '▁레', '비', '▁상', '수', '같은', '▁상', '수는', '▁다른', '▁수학', '상', '수', '▁또는', '▁함수', '와', '▁약', '한', '▁상', '관', '관', '계', '▁또는', '▁강한', '▁상', '관', '관', '계를', '▁갖', '는다', '.']\n",
      "\n",
      "10 lines : ['▁문학']\n",
      "['▁문학', '(', '文', '學', ')', '은', '▁언', '어를', '▁예술', '적', '▁표현', '의', '▁제', '재', '로', '▁삼', '아', '▁새로운', '▁의미', '를', '▁창', '출', '하여', ',', '▁인간', '과', '▁사회', '를', '▁진', '실', '되', '게', '▁묘사', '하는', '▁예술', '의', '▁하', '위', '분', '야', '이다', '.', '▁간', '단', '하게', '▁설명', '하면', ',', '▁언', '어를', '▁통해', '▁인간의', '▁삶', '을', '▁미', '적', '(', '美', '的', ')', '으로', '▁형', '상', '화', '한', '▁것이라고', '▁볼', '▁수', '▁있다', '.', '▁문학', '은', '▁원래', '▁문', '예', '(', '文', '藝', ')', '라고', '▁부', '르는', '▁것이', '▁', '옳', '으며', ',', '▁문', '학을', '▁학', '문', '의', '▁대상', '으로서', '▁탐', '구', '하는', '▁학', '문', '의', '▁명칭', '▁역시', '▁문', '예', '학', '이다', '.', '▁문', '예', '학', '은', '▁음악', '사', '학', ',', '▁미술', '사', '학', '▁등과', '▁함께', '▁예술', '학의', '▁핵', '심', '분', '야', '로서', '▁인', '문', '학의', '▁하', '위', '범', '주에', '▁포함', '된다', '.']\n",
      "['▁반', '영', '론', '적', '▁관', '점에', '▁의한', '▁감', '상은', '▁작품', '을', '▁창', '작', '된', '▁당시', '▁시대', '▁정', '황', '과', '▁연결', '시켜', '▁감', '상', '하는', '▁입', '장', '이고', ',', '▁내', '재', '적', '▁관', '점', '의', '▁감', '상은', '▁작품', '의', '▁형식', ',', '▁내용', '에', '▁국', '한', '하여', '▁감', '상', '하는', '▁것이다', '.', '▁표현', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁작가', '의', '▁전기', '적', '▁사실', '과', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것이', '고', ',', '▁수용', '론', '적', '▁관', '점', '의', '▁감', '상은', '▁독', '자와', '▁작품', '을', '▁연결', '시켜', '▁감', '상', '하는', '▁것을', '▁말한다', '.']\n",
      "\n",
      "10 lines : ['▁나라', '▁목록']\n",
      "['▁이', '▁문', '서는', '▁나라', '▁목록', '이며', ',', '▁전', '▁세계', '▁20', '6', '개', '▁나라', '의', '▁각', '▁현', '황', '과', '▁주', '권', '▁승', '인', '▁정보를', '▁개', '요', '▁형태로', '▁나', '열', '하고', '▁있다', '.']\n",
      "['▁위', '▁목록', '에', '▁포함', '되지', '▁않은', '▁다음', '▁국가', '는', '▁몬', '테', '비', '데', '오', '▁협', '약', '의', '▁모든', '▁조건', '을', '▁만족', '하지', '▁못', '하거나', ',', '▁자주', '적이고', '▁독립', '적', '임을', '▁주장', '하지', '▁않는', '▁국가', '이다', '.']\n",
      "\n",
      "['▁화학']\n",
      "['▁화학', '(', '化', '學', ',', '▁)', '은', '▁물질', '의', '▁성', '질', ',', '▁조성', ',', '▁구조', ',', '▁변화', '▁및', '▁그', '에', '▁수', '반', '하는', '▁에너', '지의', '▁변', '화를', '▁연구', '하는', '▁자연', '과', '학의', '▁한', '▁분야', '이다', '.', '▁물리', '학', '도', '▁역시', '▁물질', '을', '▁다루', '는', '▁학', '문', '이지만', ',', '▁물리', '학', '이', '▁원', '소', '와', '▁화', '합', '물을', '▁모두', '▁포함한', '▁물', '체의', '▁운동', '과', '▁에너', '지', ',', '▁열', '적', '·', '전', '기', '적', '·', '광', '학적', '·', '기', '계', '적', '▁속', '성을', '▁다루', '고', '▁이러한', '▁현', '상', '으로부터', '▁통일', '된', '▁이론', '을', '▁구축', '하려는', '▁것', '과는', '▁달리', '▁화학', '에서는', '▁물질', '▁자', '체를', '▁연구', '▁대상으로', '▁한다', '.', '▁화학', '은', '▁이미', '▁존재', '하는', '▁물질', '을', '▁이용하여', '▁특', '정한', '▁목', '적', '에', '▁맞', '는', '▁새로운', '▁물질', '을', '▁합', '성', '하는', '▁길', '을', '▁제공', '하며', ',', '▁이는', '▁농', '작', '물의', '▁증', '산', ',', '▁질', '병', '의', '▁치료', '▁및', '▁예', '방', ',', '▁에너', '지', '▁효', '율', '▁증', '대', ',', '▁환경', '오', '염', '▁감소', '▁등', '▁여러', '▁가지', '▁이', '점을', '▁제공', '한다', '.']\n",
      "['▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '해', '낸', '▁화', '합', '물을', '▁뜻', '하였으나', '▁지금', '은', '▁유', '기', '▁화', '합', '물의', '▁범', '위가', '▁크게', '▁넓', '어져', '▁탄', '소', '▁사', '슬', '▁또는', '▁탄', '소', '▁고', '리를', '▁가진', '▁모든', '▁화', '합', '물을', '▁뜻', '한다', '.', '▁유', '기', '화', '학의', '▁오', '랜', '▁관', '심', '사는', '▁유', '기', '▁화', '합', '물의', '▁합', '성', '▁메', '커', '니', '즘', '이다', '.', '▁현', '대에', '▁들어', '서', '▁핵', '자', '기', '▁공', '명', '법', '과', '▁X', '선', '▁결정', '학', '▁등이', '▁개발', '되어', '▁유', '기', '▁화', '합', '물', '▁분석', '에', '▁있어서', '▁매우', '▁중요한', '▁방법', '으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 위키가 주제별로 잘 나눠지는지 여부 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)  \n",
    "            if 0 < len(doc):\n",
    "                if 0 < count:\n",
    "                    count -= 1\n",
    "                    print(len(doc), \"lines :\", doc[0])\n",
    "                    print(doc[1])\n",
    "                    print(doc[-1])\n",
    "                    print()\n",
    "                else:\n",
    "                    break\n",
    "                doc = []\n",
    "        else:  # 빈 줄이 아니면 doc에 저장\n",
    "            pieces = vocab.encode_as_pieces(line)    \n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        print(doc[0])\n",
    "        print(doc[1])\n",
    "        print(doc[-1])\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d412f98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 105/3957761 [00:00<07:09, 9210.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc: 21 instances: 10\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '▁기간', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '쌈', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "\n",
      "doc: 14 instances: 7\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "{'tokens': ['[CLS]', '으로', '[MASK]', '잡', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "\n",
      "doc: 4 instances: 2\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '[MASK]', '았다', '[MASK]', '▁어떻', '라스', '틱', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', '[MASK]', '▁자리', '잡', '─', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "\n",
      "doc: 10 instances: 5\n",
      "{'tokens': ['[CLS]', '[MASK]', '▁자리', '시즌', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '틱', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "\n",
      "doc: 31 instances: 15\n",
      "{'tokens': ['[CLS]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 0, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "{'tokens': ['[CLS]', '으로', '▁자리', '[MASK]', '았다', '[MASK]', '[MASK]', '라스', '[MASK]', '澄', '▁합', '성', '섬', '유', '등', '의', '▁고', '분', '자', '물', '질', '▁등', '도', '▁유', '기', '화', '학', '에서', '▁다루', '어진', '다', '.', '[SEP]', '▁유', '기', '화', '학', '은', '▁탄', '소로', '▁이루어진', '▁화', '합', '물을', '▁연구', '하는', '▁분', '과', '이다', '.', '▁원래', '▁유', '기', '▁화', '합', '물', '은', '▁식물', '이나', '▁동물', '로부터', '▁추', '출', '[SEP]'], 'segment': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'is_next': 1, 'mask_idx': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'mask_label': ['으로', '▁자리', '잡', '았다', '.', '▁플', '라스', '틱', ',']}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# instance 생성 기능 확인\n",
    "count = 5\n",
    "\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    doc = []  # 단락 단위로 문서 저장\n",
    "    for line in tqdm(in_f, total=total):\n",
    "        line = line.strip()\n",
    "        if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
    "            if 0 < len(doc):\n",
    "                instances = create_pretrain_instances(vocab, doc, n_test_seq, 0.15, vocab_list)\n",
    "                # save\n",
    "                print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "                print(instances[0])\n",
    "                print(instances[-1])\n",
    "                print()\n",
    "                doc = []\n",
    "                if 0 < count:  # 테스트를 위해서 부분 처리함\n",
    "                    count -= 1\n",
    "                else:\n",
    "                    break\n",
    "        else:  # doc에 저장\n",
    "            if 0 < len(pieces):\n",
    "                doc.append(pieces)\n",
    "    if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "        instances = create_pretrain_instances(doc, 128)\n",
    "        # save\n",
    "        print(\"doc:\", len(doc), \"instances:\", len(instances))\n",
    "        print(instances[0])\n",
    "        print(instances[-1])\n",
    "        print()\n",
    "        doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1c4ecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "\n",
    "# line count 확인\n",
    "total = 0\n",
    "with open(corpus_file, 'r') as in_f:\n",
    "    for line in in_f:\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d8cba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):        # 생성되는 단어 목록이 unknown인 경우는 제거합니다. \n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            \n",
    "            ### TODO: Need to be corrected ###\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
    "                    if len(doc) > 0:  # 이전 단락 처리??\n",
    "                        save_pretrain_instances(out_f, doc)  # 인스턴스 생성 및 저장\n",
    "                        doc = []  # 새로운 단락을 위해 초기화\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)  # 문장을 pieces로 나눔\n",
    "                    if len(pieces) > 0:  # token이 존재하는 경우만\n",
    "                        doc.append(pieces)  # 문서를 doc에 추가\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                    save_pretrain_instances(out_f, doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e57f1",
   "metadata": {},
   "source": [
    "BERT pretrain 데이터셋을 생성해, json 포맷으로 저장하세요.   \n",
    "데이터셋의 사이즈가 크므로np.memmap을 사용해 메모리 사용량을 최소화해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28fd13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3957761/3957761 [04:53<00:00, 13503.47it/s]\n"
     ]
    }
   ],
   "source": [
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/bert_pretrain/data/bert_project_train.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f07121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 큰 파일을 로딩하는 함수를 만들 때는 메모리 사용량과 관련해 고려해야 할 점\n",
    "# np.memmap을 사용해서 메모리 사용량을 최소화\n",
    "\n",
    "n_seq = 128\n",
    "# [CLS], tokens_a, [SEP], tokens_b, [SEP]\n",
    "max_seq = n_seq - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "519dc4ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noraml Array\n",
    "enc_tokens = np.zeros((total, n_seq), np.int32)\n",
    "dec_tokens = np.zeros((total, n_seq), np.int32)\n",
    "labels_nsp = np.zeros((total,), np.int32)\n",
    "labels_mlm = np.zeros((total, n_seq), np.int32)\n",
    "enc_tokens[0], enc_tokens[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "774872da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " 0,\n",
       " 0,\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.memmap \n",
    "enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "\n",
    "enc_tokens[0], enc_tokens[-1], segments[0], segments[-1], labels_nsp[0], labels_nsp[-1], labels_mlm[0], labels_mlm[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "247e2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f98a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/128000 [00:00<?, ?it/s]/tmp/ipykernel_31/2049745891.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_31/2049745891.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_31/2049745891.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
      "100%|██████████| 128000/128000 [00:23<00:00, 5563.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 128000건만 메모리에 로딩\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26183034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(memmap([   5,    6,    6,    6,    6,    6,    6,    6,    6,    6,    6,\n",
       "            6, 2404,    6,    6,    6,    6,    6, 3008, 3625, 3616,   16,\n",
       "         3599,   18, 3686,  207, 3714, 3602, 1755, 3630, 3646,  630, 3714,\n",
       "         3565, 3835,  429, 3740, 3628, 3626, 1369,   10, 1605, 3599, 1755,\n",
       "         3630,   41, 3644,  830, 3624, 1135,   52, 3599,   13,   81,   87,\n",
       "         1501, 2247,   25, 3779, 3873, 3667, 3631, 3813, 3873, 4196, 3636,\n",
       "         3779, 3601,  249, 3725, 1232,   33,   52, 3599,  479, 3652, 3625,\n",
       "          243, 2780,   14, 1509,  168, 3877,  414,  165, 1697, 4290, 3873,\n",
       "         3703, 3683,  593,   21, 5007,  399, 1927, 3607,  813,   17, 3599,\n",
       "          307,  587,  931,  103, 4313, 4290,  613, 3638, 3718,   98, 3878,\n",
       "         3656,  256, 2543,  309,  337, 3735,  181, 3616, 3603,  489,  376,\n",
       "         3599,    4,   18, 3686,  207, 3714,    4], dtype=int32),\n",
       " memmap([   5,    6,    6,    6,    6,    6,    6,    6,    6,    6, 6380,\n",
       "            6,    6,    6,    6,    6, 3620,    6,    6, 3608,  347,  176,\n",
       "          268, 4082,   94,  567, 4014, 3617, 7474, 3616, 3830,   66, 3590,\n",
       "          307,  192, 1272,  158, 3788,  353, 3599,  202,  316, 3600,  176,\n",
       "           10,  323,  476, 3663, 1329,  605,  238, 3631, 2470, 3604, 1939,\n",
       "          106, 3627,   13,  162,  490, 1128,   48,   28, 3599,    4,  848,\n",
       "         3784, 3833,    8, 3637, 2263, 2316, 3619,  169, 1617, 3883, 3756,\n",
       "           60, 1255, 3743, 3623,   10, 1605, 3599,  135, 4181,   84, 3604,\n",
       "         1543, 3638, 3612, 3883, 1357,   10, 3571, 3645, 3672, 3610,  101,\n",
       "         4274, 4268, 3602, 2108, 3607, 2991, 3654,   76, 3684,   54,   41,\n",
       "         2429, 4143,  405, 1184, 3600, 2972,  173,  351, 3599,  269,  820,\n",
       "          477, 3921,   66, 1357, 3715, 3633,    4], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=int32),\n",
       " memmap([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32),\n",
       " 0,\n",
       " 1,\n",
       " memmap([   0, 3629,  203,  241, 3602, 1114, 3724,  788,  243,   49, 3632,\n",
       "          796,  663, 1647, 3682, 3682, 3625,  203, 3008,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32),\n",
       " memmap([   0, 3604, 2375, 3608, 3604,  532, 2589, 3599,  307,  323, 2143,\n",
       "          321, 3611,  622,  122, 3725, 3620, 3627, 3837,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0], dtype=int32))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 처음과 마지막 확인\n",
    "pre_train_inputs[0][0], pre_train_inputs[0][-1], pre_train_inputs[1][0], pre_train_inputs[1][-1], pre_train_labels[0][0], pre_train_labels[0][-1], pre_train_labels[1][0], pre_train_labels[1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a1e35c",
   "metadata": {},
   "source": [
    "\n",
    "#### BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93929b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71abf753",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7c64b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eec7a414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2b8a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token Embedding\n",
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13dbde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position Embedding은 위치 정보가 담긴 임베딩 레이어를 하나 더 사용해 \n",
    "# Position Embedding 벡터를 학습시켜서, BERT의 입력에 Position Embedding을 더함\n",
    "\n",
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19c2af41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10825e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "\n",
    "        attn_out = self.attention(Q_m, K_m, V_m, attn_mask_m)  # (bs, n_head, Q_len, d_head)\n",
    "        attn_out_m = tf.transpose(attn_out, perm=[0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out_m, [batch_size, -1, config.n_head * config.d_head])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9417ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5a55f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "455d4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d8b60655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aef467a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55c17a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'d_model': 256,\n",
       " 'n_head': 4,\n",
       " 'd_head': 64,\n",
       " 'dropout': 0.1,\n",
       " 'd_ff': 1024,\n",
       " 'layernorm_epsilon': 0.001,\n",
       " 'n_layer': 3,\n",
       " 'n_seq': 256,\n",
       " 'n_vocab': 8007,\n",
       " 'i_pad': 0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6886a560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 18s 13ms/step - loss: 9.7854 - nsp_loss: 0.7561 - mlm_loss: 9.0293 - nsp_acc: 0.5000 - mlm_acc: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 8.5865 - nsp_loss: 0.6392 - mlm_loss: 7.9472 - nsp_acc: 0.6000 - mlm_acc: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7e944af0c2e0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# n_seq = 10\n",
    "\n",
    "# # make test inputs\n",
    "# enc_tokens = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "# segments = np.random.randint(0, 2, (10, n_seq))\n",
    "# labels_nsp = np.random.randint(0, 2, (10,))\n",
    "# labels_mlm = np.random.randint(0, len(vocab), (10, n_seq))\n",
    "\n",
    "# test_model = build_model_pre_train(config)\n",
    "# test_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy, optimizer=tf.keras.optimizers.Adam(), metrics=[\"acc\"])\n",
    "\n",
    "# # test model fit\n",
    "# test_model.fit((enc_tokens, segments), (labels_nsp, labels_mlm), epochs=2, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29591dc9",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "47d4e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K  # Keras Backend 추가\n",
    "\n",
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴\n",
    "\n",
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8e747589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "def39ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAArNElEQVR4nO3deZRU1bn38e9DMykiQwNhtlFwYI52RI1eUVTAiajEYLyKBiVGjTHGOKArr3p1Jaj3mphoFIfEIRGMGm0j4qxxGQGbKkAG0RZUcAREUIOM+/1j7w5t20N1d1XtqurfZ61aVXXq1D5PVUM/vc+zz97mnENERCQVLWIHICIi+UNJQ0REUqakISIiKVPSEBGRlClpiIhIylrGDiCTunTp4kpKSmKHISKSV+bNm7fGOde1ptcKOmmUlJRQXl4eOwwRkbxiZu/W9ppOT4mISMqUNEREJGVKGiIikjIlDRERSZmShoiIpCylpGFmY8xsmZlVmNllNbzexsxmhNfnmFlJldcuD9uXmdno+to0s7+E7YvM7G4zaxW2jzSz9WY2P9x+1aRPLiIiDVZv0jCzIuAWYCwwEDjFzAZW220SsM451x+4CZga3jsQmAAMAsYAt5pZUT1t/gXYGxgC7AScVeU4LzvnhofbNY35wCIi0nipXKexP1DhnFsOYGbTgXHAkir7jAOuCo8fAv5gZha2T3fObQJWmFlFaI/a2nTOzaxs1MzmAr0b+dkKz9atcPPN8O9/Q5s20LatvxUXQ7du0LWrv+/YEcxiRysiBSiVpNELWFnl+SpgRG37OOe2mtl6oDhsn13tvb3C4zrbDKelTgN+VmXzgWa2APgAuNg5t7h6sGY2GZgM0Ldv3xQ+Xh558UX4xS/q369DB9hjD+jf39+GDoV99/XbWqiMJSKNl8tXhN8K/NM593J4ngB2c859YWZHA48CA6q/yTk3DZgGUFpaWlgrTCUS/v7DD6FdO9i0CTZuhLVr4ZNPYPVq+OgjWLECKir8/o884nsoAO3bw/Dh8N3vwqGH+vv27aN9HBHJP6kkjfeBPlWe9w7batpnlZm1BDoAa+t5b61tmtn/A7oCP67c5pzbUOXxTDO71cy6OOfWpPAZCkMyCbvtBt27++eVv/D79Kn9PZs3w5IlPoEkElBeDjfeCL/5DRQVQWkpjB4Nxx/veyM6rSUidUjlXMVrwAAz62dmrfGF7bJq+5QBE8Pj8cDzzq8jWwZMCKOr+uF7BnPratPMzgJGA6c457ZXHsDMuoc6CWa2f4h9bWM+dN5KJODb327Ye1q39r2LH/0I/vAHmD0bPvsMnn4aLr3UJ4lrr/XJo08f+MlP4NlnYdu2THwCEclz9fY0Qo3ifOApoAi42zm32MyuAcqdc2XAXcB9odD9KT4JEPZ7EF803wqc55zbBlBTm+GQtwHvAq+GHPFIGCk1HviJmW0FNgITXHNa4PyLL+Ctt+DUU5veVrt2cOSR/gb+tNbMmVBWBvfdB7fdBj16wA9/CP/93zBsmHogIgKAFfLv3dLSUlcws9y+8gocfDA8/jgce2zmjvPVV/DEEz55zJwJW7bAkCFwzjlw2mmqgYg0A2Y2zzlXWtNrGkqTLyqL4A09PdVQbdvCSSfBo4/6gvutt/pTXOedBz17+vtFizIbg4jkLCWNfJFM+mswevbM3jGLi32N47XXfC3kxBPhrrt8z2PMGHjpJSjgnqqIfJOSRr6oLILHqC2YwYgRcM89sGoVXHedT2IjR/phu48/Dtu319uMiOQ/JY18sGkTLF6c+VNTqejSBaZMgXfegVtu8aewKofrPvGEeh4iBU5JIx8sXuwv0Nt339iR7LDTTnDuufDmm3DvvX5017HHwiGHwMsv1/9+EclLShr5IFtF8MZo1cqPqlq61A/VXb4c/uu/YOxYn+xEpKAoaeSDZBJ23RV23z12JLVr1Qp+/GM/fcn11/vC+bBhcMEFsG5d7OhEJE2UNPJBMumv6s6HyQZ33hl++Ut/IeLkyb7uMWCA74XoKnORvJcHv4WauW3bYMGC3Dw1VZcuXfw1HokEDB7sh+5+5zswb17syESkCZQ0ct2bb/r1M3KpCN4Qw4bBCy/AjBl+Bt799/fTu3/5ZezIRKQRlDRyXS4XwVNlBief7GfbPfts+L//872Pp56KHZmINJCSRq5LJv0qfXvvHTuSpuvY0dc2/vlPP13JmDFwxhmwfn3syEQkRUoauS6Z9CvvtWoVO5L0OeQQmD8frrjCT4w4dKhflVBEcp6SRi5zrnFraOSDNm38Oh6vvOIfH3YYXHSRn2VXRHKWkkYue/ddv2BSvhbBU3HAAb43de65cNNNsN9+frSYiOQkJY1cVghF8FS0a+ev55g1y18IOGIE3H675rESyUFKGrksmfTreA8ZEjuS7Bg92vcyDjvML/o0YYKK5CI5RkkjlyWTsM8+fnLA5qJrVz9b7m9+Aw8/7E/NFcrqiyIFQEkjlxVqEbw+LVrApZf6oblbtsBBB/mry3W6SiQ6JY1c9fHHfq2K5pg0Kh10kB+ae9RRfpnZSZM0ukokMiWNXJVM+vtCHjmVis6doawMfvUr+NOf/LTrK1fGjkqk2VLSyFWVI6eGD48aRk5o0QKuvhoefRTeeANKS/2pKxHJOiWNXJVMwh57QIcOsSPJHePGwdy50KkTjBrlh+mKSFYpaeSq5loEr8/ee/vEMXYsnH++v23dGjsqkWZDSSMXrV/vl01V0qjZrrvC3/8OF1/sexvHHQcbNsSOSqRZUNLIRfPn+/vmXgSvS1ER3HADTJsGzz4L3/2un3ZFRDJKSSMXNZfpQ9Lh7LP99CMrV/oFnmbPjh2RSEFT0shFyST07Anf+lbsSPLDqFHw6quwyy5+CpK//z12RCIFS0kjFyWT6mU01D77+F7G8OEwfryf8FBE0k5JI9ds3AhLlyppNEbXrr6+MXasn/Dwqqs09YhImilp5JrXX4dt21QEb6x27fzpqTPP9BcEnnOO/z5FJC1SShpmNsbMlplZhZldVsPrbcxsRnh9jpmVVHnt8rB9mZmNrq9NM/tL2L7IzO42s1Zhu5nZzWH/hWZWmL9VVQRvulat4K67YMoUP7pq/HjfgxORJqs3aZhZEXALMBYYCJxiZgOr7TYJWOec6w/cBEwN7x0ITAAGAWOAW82sqJ42/wLsDQwBdgLOCtvHAgPCbTLwx8Z84JyXTPornnfbLXYk+c0MrrsObr4ZHnvMT3qotTlEmiyVnsb+QIVzbrlzbjMwHRhXbZ9xwD3h8UPAKDOzsH26c26Tc24FUBHaq7VN59xMFwBzgd5VjnFveGk20NHMejTyc+euyiK4WexICsNPfwrTp8OcOXD44bBmTeyIRPJaKkmjF1B1WtFVYVuN+zjntgLrgeI63ltvm+G01GnArAbEgZlNNrNyMytfvXp1Ch8vh2zZAgsX6tRUup18su9tLFkChx7qp5wXkUbJ5UL4rcA/nXMvN+RNzrlpzrlS51xp165dMxRahrzxBmzapCJ4JowdC08+Ce+9B4ccoqvHRRoplaTxPtCnyvPeYVuN+5hZS6ADsLaO99bZppn9P6ArcFED48hvKoJn1siRfkju2rVw8MHw5puxIxLJO6kkjdeAAWbWz8xa4wvbZdX2KQMmhsfjgedDTaIMmBBGV/XDF7Hn1tWmmZ0FjAZOcc5tr3aM08MoqgOA9c65wjrPkEzCzjvDnnvGjqRwjRgBL77oe3SHHOJPB4pIyupNGqFGcT7wFLAUeNA5t9jMrjGz48NudwHFZlaB7x1cFt67GHgQWIKvTZznnNtWW5uhrduAbwGvmtl8M/tV2D4TWI4vpt8BnNu0j56DkkkYNsxPxieZM2wYvPyyH5o7ciTMmxc7IpG8Ya6Ar5gtLS115eXlscNIzfbt0LEjnHaaFhfKlhUr/Iiqzz7zp6322y92RCI5wczmOedKa3otlwvhzcvy5fD55yqCZ1O/fvDCCz5ZH3GEehwiKVDSyBXJpL9XETy7Skp8jaMyceRLz1QkEiWNXJFIQMuWMGhQ7Eian91225E4jjxSiUOkDkoauSKZhMGDoU2b2JE0T5WJo1MnJQ6ROihp5ALnfE9Dp6bi2m03X+NQ4hCplZJGLvjgA1i9WkkjF1TvcSxYEDsikZyipJELKovgGjmVG/r2heefh/btfeJYujR2RCI5Q0kjFyQSflbbYcNiRyKVSkrguef8hZajRsHbb8eOSCQnKGnkgmTSTx2yyy6xI5GqBgzwF/1t3uwTx3vvxY5IJDoljVygInjuGjQInn7aXzV+xBHw0UexIxKJSkkjtrVr/V+wShq5a999/bTqH3zgE4cWcpJmTEkjtvnz/b2K4LntwAPh8cd9beOoo3zPQ6QZUtKITWto5I/DDoNHHoFFi+Doo+HLL2NHJJJ1ShqxJZN+iGdxcexIJBVjx+5Yc3z8eF8kF2lGlDRiSybVy8g3J54I06bBrFkwcaKf1l6kmWgZO4Bm7YsvYNkymDAhdiTSUJMm+UEMl17qe4m//72/1kakwClpxLRwoZ93SkXw/HTJJX4k1Q03QJcucNVVsSMSyTgljZhUBM9/U6f6HsfVV/sex09/GjsikYxS0ogpmfR/ofbqFTsSaSwzuP12+PRTuOAC6NwZTj01dlQiGaNCeEzJpD81pXPh+a1lS3jgARg5Es44w18IKFKglDRi2bzZj/fXqanC0LYtPPYYDB0KJ50Er7wSOyKRjFDSiGXxYtiyRUXwQrLrrr6X0acPHHccLFkSOyKRtFPSiKVyDQ31NApLt27w1FN+2d4xY+D992NHJJJWShqxJBJ+kZ899ogdiaRbSQnMnAnr1vnpRtavjx2RSNooacSSTMLw4dBCP4KC9O1v+3mqliyBE06ATZtiRySSFvqNFcO2bX52W52aKmxHHgl33w0vvABnnqnpRqQg6DqNGN56C/79byWN5uC00/w6HJdd5q/HueGG2BGJNImSRgyVRXCNnGoeLrnEF8RvvNEnjgsvjB2RSKMpacSQSPjRNfvsEzsSyQYzuOkm3+O46CLo2RNOPjl2VCKNoppGDMkkDBkCrVrFjkSypagI7r8fDj7Yn7J66aXYEYk0SkpJw8zGmNkyM6sws8tqeL2Nmc0Ir88xs5Iqr10eti8zs9H1tWlm54dtzsy6VNk+0szWm9n8cPtVoz91TM75nobqGc1P5VXj/fvDuHF+RgCRPFNv0jCzIuAWYCwwEDjFzAZW220SsM451x+4CZga3jsQmAAMAsYAt5pZUT1tvgIcAbxbQzgvO+eGh9s1DfuoOeK99/z4fSWN5qlTJ3/VeLt2/uK/VatiRyTSIKn0NPYHKpxzy51zm4HpwLhq+4wD7gmPHwJGmZmF7dOdc5uccyuAitBerW0655LOuXea+Llyl4rg0revTxwbNsCxx/p7kTyRStLoBays8nxV2FbjPs65rcB6oLiO96bSZk0ONLMFZvakmQ2qaQczm2xm5WZWvnr16hSazLJEwl/QN2RI7EgkpqFD4aGH/Cmqk0/285CJ5IF8KoQngN2cc8OA3wOP1rSTc26ac67UOVfatWvXbMaXmmTSj5raeefYkUhsRx0Ft93m56o67zxf7xLJcakkjfeBPlWe9w7batzHzFoCHYC1dbw3lTa/xjm3wTn3RXg8E2hVtVCeN5JJ1TNkh7POgilT4I474PrrY0cjUq9UksZrwAAz62dmrfGF7bJq+5QBE8Pj8cDzzjkXtk8Io6v6AQOAuSm2+TVm1j3USTCz/UPsa1P5kDnjk0/8RV5KGlLV//wPnHKKv2p8xozY0YjUqd6L+5xzW83sfOApoAi42zm32MyuAcqdc2XAXcB9ZlYBfIpPAoT9HgSWAFuB85xz28APra3eZth+AXAJ0B1YaGYznXNn4ZPRT8xsK7ARmBASU/5QEVxq0qIF/OlPfiTV6af7q8YPPjh2VCI1snz7vdsQpaWlrry8PHYYO/z61/5UxLp10LFj7Ggk13z6KRx0EKxeDa++CnvuGTsiaabMbJ5zrrSm1/KpEJ7/kkno108JQ2rWubNfh6OoyK/DkYuj/6TZU9LIpmRSp6akbrvvDmVlvvY1bhxs3Bg7IpGvUdLIlvXroaJCRXCp3wEH+HmqZs/281RpHQ7JIUoa2bJggb9XT0NScdJJfir1hx+GSy+NHY3If2hq9GxJJPy9ehqSqp//HJYv98mjXz8499zYEYkoaWRNMgndu/ubSCrM4Le/hXffhZ/+FHbbDY45JnZU0szp9FS2qAgujdGyJUyf7nuoP/jBjh6rSCRKGtmwcSMsWaJTU9I47drB449DcbGfFXflyvrfI5IhShrZsGgRbNumnoY0Xo8e8MQT8OWX/hqO9etjRyTNlJJGNlROH6KehjTF4MF+NNUbb8D3v6/p1CUKJY1sSCT8VeAlJbEjkXx3xBFw++3wzDN+NFUBTwMkuUmjp7Khcjp0P0mvSNP86Ed+KO5118Eee/jZcUWyRD2NTNu6FRYu1KkpSa/K6dQvv9yPrhLJEvU0Mu2NN+Crr5Q0JL3MdkynfsYZ0Lu3plOXrFBPI9O0hoZkSps28Pe/Q9++fnLDt96KHZE0A0oamZZIwE47wV57xY5EClFxsZ9OvUULPxR3zZrYEUmBU9LItGQShg3zaySIZEL//vDYY/6iv+99z58OFckQJY1M2r59x8gpkUw66CC47z545RVf49B06pIhShqZtGIFbNigpCHZ8f3vw9SpMGMGXHll7GikQGn0VCapCC7Z9stfwttv+/Xo+/WDs8+OHZEUGCWNTEok/CylgwfHjkSaCzO45RZ47z34yU/8dOpHHRU7KikgOj2VSckkDBrkh0aKZEvLlv4U1aBBMH48vP567IikgChpZIpzvqeheobEsOuuflbc9u39UNwPPogdkRQIJY1M+fBD+OQTJQ2Jp3dvnzg++8yvw/HFF7EjkgKgpJEpKoJLLhg+3J+qWrAAJkzwc6GJNIGSRqYkEr4oOWxY7EikuTv6aF8cf+IJuPBCTacuTaLRU5mSTPorddu3jx2JCJxzjh+Ke+ONfjr1n/88dkSSp5Q0MiWZhBEjYkchssPUqf6C01/8wi8IdsIJsSOSPKTTU5nw6afwzjsqgktuadHCTzUyYgSceirMmRM7IslDShqZMH++v1cRXHLNTjv5yQ27d4fjjvM9D5EGUNLIhMqRU+ppSC7q1s1Pp751qy+Sr1sXOyLJIyklDTMbY2bLzKzCzL6xILGZtTGzGeH1OWZWUuW1y8P2ZWY2ur42zez8sM2ZWZcq283Mbg6vLTSz3P0zPpHwY+S7dKl/X5EY9t7bL+D09ttw4omweXPsiCRP1Js0zKwIuAUYCwwETjGzgdV2mwSsc871B24Cpob3DgQmAIOAMcCtZlZUT5uvAEcA71Y7xlhgQLhNBv7YsI+aRcmkTk1J7jv0UL9k7IsvwllnaSiupCSVnsb+QIVzbrlzbjMwHRhXbZ9xwD3h8UPAKDOzsH26c26Tc24FUBHaq7VN51zSOfdODXGMA+513mygo5n1aMiHzYovv/TrguvUlOSDU0+Fa67xBfJrrokdjeSBVJJGL2BlleerwrYa93HObQXWA8V1vDeVNhsTB2Y22czKzax89erV9TSZAQsX+r/YlDQkX1x5pV+46aqr4N57Y0cjOa7gCuHOuWnOuVLnXGnXrl2zH4CmD5F8Ywa33w6HH+5PU734YuyIJIelkjTeB/pUed47bKtxHzNrCXQA1tbx3lTabEwc8SUSUFzsC+Ei+aJ1a3j4YRgwwF/0t3Rp7IgkR6WSNF4DBphZPzNrjS9sl1XbpwyYGB6PB553zrmwfUIYXdUPX8Sem2Kb1ZUBp4dRVAcA651zH6YQf3ZVFsHNYkci0jAdO/r5qdq08UNxP/44dkSSg+pNGqFGcT7wFLAUeNA5t9jMrjGz48NudwHFZlYBXARcFt67GHgQWALMAs5zzm2rrU0AM7vAzFbhexILzezOcIyZwHJ8Mf0O4Nwmf/p027zZL3ijeobkq5IS+Mc//LT+xxwDn38eOyLJMeYKeJhdaWmpKy8vz94B58/3CeOBB/w01CL56oknYNw4GDUKHn/cn76SZsPM5jnnSmt6reAK4VGpCC6F4phj4I474Omn4Uc/gu3bY0ckOUKz3KZTIgG77OKnRBfJd2ee6VegvOIK6NEDbrghdkSSA5Q00imZ9CultVAHTgrE5Zf79cVvvNEnjosuih2RRKbfbumyffuOmoZIoTCD3/0OTjrJr8PxwAOxI5LI1NNIl7fe8lOIKGlIoSkqgvvvhzVrYOJE6NoVjjgidlQSiXoa6aIiuBSytm3h0Uf97LgnnODrd9IsKWmkSyLhhyUOrD4BsEiB6NgRnnwSOneGsWP9tOrS7ChppEsyCYMHQ6tWsSMRyZxevWDWLL+A05gx/iJAaVaUNNLBOa2hIc3HPvv4q8bff9/3ODZsiB2RZJGSRjqsXAlr16oILs3HgQfC3/7mlwI47jjYuDF2RJIlShrpoCK4NEfHHOPX33j5ZTj5ZNiyJXZEkgVKGumQSPgL+oYOjR2JSHadcgrceqs/XXXGGZpupBnQdRrpkEzCXnvBzjvHjkQk+845B9atgylT/AirP/xBSwMUMCWNdEgm4dBDY0chEs9ll/nEccMN0KkTXHtt7IgkQ5Q0mmr1ali1SkVwad7MYOpU+OwzuO46nzh+8YvYUUkGKGk0lYrgIp4Z/PGPsH49XHyxP1U1aVLsqCTNlDSaqjJpDB8eNQyRnFBUBPfd56/dmDwZdt0Vvv/92FFJGmn0VFMlEn6JzE6dYkcikhtat4aHHvLXcvzwh/DYY7EjkjRS0mgqXQku8k3t2sHMmbDffr6nMXNm7IgkTZQ0mmLDBj8luorgIt+0665+nqohQ+DEE+GZZ2JHJGmgpNEUCxb4eyUNkZp17OjXGd9rLxg3Dl58MXZE0kRKGk2hkVMi9SsuhmefhX794Nhj4ZVXYkckTaCk0RSJBHzrW37tZBGpXdeu8Nxzfmr1sWNhzpzYEUkjKWk0hYrgIqnr3h2efx66dYPRo2HevNgRSSMoaTTWV1/BkiWqZ4g0RK9ePnF07OjXGS8vjx2RNJCSRmMtWuRXL1PSEGmYvn19QbxTJxg1CmbPjh2RNICSRmOpCC7SeCUl8NJLvtZx1FEqjucRJY3GSiSgQwc/IkREGq5PH584evTwNY6XXoodkaRASaOxkkk/35TWDRBpvF69fLLo29ePqnruudgRST2UNBpj61a/NrJOTYk0XffuvsbRv7+/juOpp2JHJHVIKWmY2RgzW2ZmFWZ2WQ2vtzGzGeH1OWZWUuW1y8P2ZWY2ur42zaxfaKMitNk6bD/DzFab2fxwO6tJn7wpli2DjRtVBBdJl27d/KiqvfeG44+HsrLYEUkt6k0aZlYE3AKMBQYCp5jZwGq7TQLWOef6AzcBU8N7BwITgEHAGOBWMyuqp82pwE2hrXWh7UoznHPDw+3ORn3idFARXCT9unTxp6eGD/dzVd17b+yIpAap9DT2Byqcc8udc5uB6cC4avuMA+4Jjx8CRpmZhe3TnXObnHMrgIrQXo1thvccHtogtPm9Rn+6TEkkoG1bP5+OiKRP585+ypGRI2HiRPjd72JHJNWkkjR6ASurPF8VttW4j3NuK7AeKK7jvbVtLwY+C23UdKyTzGyhmT1kZn1qCtbMJptZuZmVr169OoWP1wjJJAwdCi21hpVI2rVvD088ASecABdeCFddBc7FjkqCfCqEPw6UOOeGAs+wo2fzNc65ac65UudcadeuXdMfhXOaPkQk09q0gQcfhDPPhKuvhp/9DLZvjx2VkNpyr+8DVf+q7x221bTPKjNrCXQA1tbz3pq2rwU6mlnL0Nv4z/7OubVV9r8TuD6F2NNvxQq/BrKK4CKZ1bIl3HWXP2X1v/8L69bB3XdDq1axI2vWUulpvAYMCKOaWuML29WHNpQBE8Pj8cDzzjkXtk8Io6v6AQOAubW1Gd7zQmiD0OZjAGZWdSrZ44GlDfuoaaIiuEj2mMENN8B118H99/uRVZ9/HjuqZq3enoZzbquZnQ88BRQBdzvnFpvZNUC5c64MuAu4z8wqgE/xSYCw34PAEmArcJ5zbhtATW2GQ14KTDeza4FkaBvgAjM7PrTzKXBGkz99YySTUFQEgwdHObxIs2MGU6b4YbnnnAOHHuprHlqSIApzBVxgKi0tdeXpnkXz6KNh1Sp/cZ+IZNeTT/o1x4uL/eOB1Uf/SzqY2TznXGlNr+VTITw3qAguEs/YsfDPf8LmzXDQQVo+NgIljYb48EP46CMVwUVi2ndfePVV6NnTT3T417/GjqhZUdJoiMoiuJKGSFwlJX469QMPhFNP9cNyNSQ3K5Q0GqIyaQwfHjUMEcEv4vTUU3D66f4CwB/8AL78MnZUBU9JoyESCT8T5667xo5ERMBfBPjnP/thuQ8/DIccAu+9Fzuqgqak0RAqgovkHjO4+GL4xz/g7bfhO9+Bf/0rdlQFS0kjVevW+avBVc8QyU1HH+3XG2/fHg47zF89LmmnpJGq+fP9vZKGSO7aZx+YO9efppo0Cc4+G776KnZUBUVJI1UaOSWSHzp39gXyKVPgzjv99RzLl8eOqmAoaaQqkfDrGXfrFjsSEalPUZGfr6qszJ9W3m8/X/OQJlPSSJWK4CL557jjYN482H13/3jKFNiyJXZUeU1JIxX//je88YZOTYnko9139xcCnn02/PrXvt7x9tuxo8pbShqpWLjQX22qpCGSn9q2hWnTYMYM/wfg8OF+DfICnrA1U5Q0UqE1NEQKw8kn+z8Cv/1tvwb5qaf6RdUkZUoaqUgk/IiMPjUuSy4i+aRvX3jhBbj2Wr+k7LBh8NxzsaPKG0oaqUgm/V8mZrEjEZF0KCqCK67wtY42beCII+DHP4YNG2JHlvOUNOqzZQu8/rpOTYkUohEj/IW7F1/sr+kYNAhmzYodVU5T0qjPkiV+wRcVwUUK0047+QkP//UvPxnp2LFwxhmwenXsyHKSkkZ9VAQXaR5GjPD1yylT4C9/gb32gttvh23bYkeWU5Q06pNMQrt2MGBA7EhEJNPatPFXks+fD0OHwjnn+IWeystjR5YzlDTqk0j40RUt9FWJNBuDBvkRVvff79fn2H9/Xyj/6KPYkUWn34R12b7d/8WhU1MizY+Zv45j2TK44AI/1Xr//n6VwC++iB1dNEoadamo8P84VAQXab46dIDf/haWLvVF8quv9snj9tub5TxWShp1URFcRCr17w9/+xu8+qp/fM45vlh+551+hGUzoaRRl2QSWrWCgQNjRyIiueKAA+Dll+Hxx6G42E+EuOeevuexaVPs6DJOSaMuiQQMHgytW8eORERyiRkce6xfJXDmTOje3fc8+vXzo68K+BoPJY3aOKc1NESkbma+zvHqq/D00zBkCFx5pZ+n7qyz/GwSBUZJozarVsGaNSqCi0j9zODII/0ys4sX+yvK//pXf63HgQfCHXcUzLxWShq10ZrgItIYAwfCbbfBypV+epING2DyZH8K6/TTfWLJ41FXShq1SSb9Xw/DhsWORETyUXGxnwhx0SKYPdsnjMcegzFjoFs3v55HWRls3Bg70gZR0qhNIuGH07VrFzsSEclnZn5eq9tug48/9onj+ON9whg3zq/VM3q075XMn+8vKs5hKSUNMxtjZsvMrMLMLqvh9TZmNiO8PsfMSqq8dnnYvszMRtfXppn1C21UhDZb13eMjFARXETSrW1bnzDuuccnkFmz/PQkq1bBJZf40+HdusHRR/srz598MudGYrWsbwczKwJuAY4EVgGvmVmZc25Jld0mAeucc/3NbAIwFfiBmQ0EJgCDgJ7As2a2Z3hPbW1OBW5yzk03s9tC23+s7RhN/QJqtGaNPx+peoaIZErr1r6HMTr8Lf3BB/Dss/DSS34o76xZO9Yw79oV9t7b3/baC3r3hp49/a17d9h556wtEldv0gD2Byqcc8sBzGw6MA6omjTGAVeFxw8BfzAzC9unO+c2ASvMrCK0R01tmtlS4HDgh2Gfe0K7f6ztGM5lYGV4FcFFJNt69vR1j9NP988//xzmzfO3N97wt0cegbVrv/neFi1gl138beedoWVLf9HhRRelPcxUkkYvYGWV56uAEbXt45zbambrgeKwfXa19/YKj2tqsxj4zDm3tYb9azvGmqqBmNlkYDJA3759U/h4NdhpJzjuOCUNEYmnfXsYOdLfqlq3zvdKKm8ffeQTzJdf+rnyvvzSrwHSvXtGwkolaeQV59w0YBpAaWlp43ohBx/sbyIiuaZTJ38bNCjK4VMphL8P9KnyvHfYVuM+ZtYS6ACsreO9tW1fC3QMbVQ/Vm3HEBGRLEklabwGDAijmlrjC9tl1fYpAyaGx+OB50OtoQyYEEY+9QMGAHNrazO854XQBqHNx+o5hoiIZEm9p6dC/eB84CmgCLjbObfYzK4Byp1zZcBdwH2h0P0pPgkQ9nsQXzTfCpznnNsGUFOb4ZCXAtPN7FogGdqmtmOIiEj2WCH/sV5aWurKtbaviEiDmNk851xpTa/pinAREUmZkoaIiKRMSUNERFKmpCEiIikr6EK4ma0G3m3k27tQ7WrzHJGrcUHuxqa4GkZxNUwhxrWbc65rTS8UdNJoCjMrr230QEy5GhfkbmyKq2EUV8M0t7h0ekpERFKmpCEiIilT0qjdtNgB1CJX44LcjU1xNYziaphmFZdqGiIikjL1NEREJGVKGiIikjIljRqY2RgzW2ZmFWZ2WYTjv2Nmr5vZfDMrD9s6m9kzZvZWuO8UtpuZ3RxiXWhm+6YxjrvN7BMzW1RlW4PjMLOJYf+3zGxiTcdKQ1xXmdn74Tubb2ZHV3nt8hDXMjMbXWV7Wn/OZtbHzF4wsyVmttjMfha2R/3O6ogr6ndmZm3NbK6ZLQhxXR229zOzOeEYM8LyCZhfYmFG2D7HzErqizfNcf3ZzFZU+b6Gh+1Z+7cf2iwys6SZ/SM8z+735ZzTrcoNP1X728DuQGtgATAwyzG8A3Sptu164LLw+DJganh8NPAkYMABwJw0xvFfwL7AosbGAXQGlof7TuFxpwzEdRVwcQ37Dgw/wzZAv/CzLcrEzxnoAewbHrcH3gzHj/qd1RFX1O8sfO5dwuNWwJzwPTwITAjbbwN+Eh6fC9wWHk8AZtQVbwbi+jMwvob9s/ZvP7R7EfBX4B/heVa/L/U0vml/oMI5t9w5txmYDoyLHBP4GO4Jj+8Bvldl+73Om41f+bBHOg7onPsnfu2SpsQxGnjGOfepc24d8AwwJgNx1WYcMN05t8k5twKowP+M0/5zds596JxLhMefA0vxa9tH/c7qiKs2WfnOwuf+IjxtFW4OOBx4KGyv/n1Vfo8PAaPMzOqIN91x1SZr//bNrDdwDHBneG5k+ftS0vimXsDKKs9XUfd/sExwwNNmNs/MJodt33LOfRgefwR8KzzOdrwNjSOb8Z0fTg/cXXkKKFZc4VTAt/F/pebMd1YtLoj8nYVTLfOBT/C/VN8GPnPOba3hGP85fnh9PVCcjbicc5Xf13Xh+7rJzNpUj6va8TPxc/wtcAmwPTwvJsvfl5JGbjrYObcvMBY4z8z+q+qLzvcxo4+VzpU4gj8CewDDgQ+B/40ViJntAjwMXOic21D1tZjfWQ1xRf/OnHPbnHPDgd74v3b3znYMNakel5kNBi7Hx/cd/CmnS7MZk5kdC3zinJuXzeNWp6TxTe8Dfao87x22ZY1z7v1w/wnwd/x/po8rTzuF+0/C7tmOt6FxZCU+59zH4T/6duAOdnS3sxqXmbXC/2L+i3PukbA5+ndWU1y58p2FWD4DXgAOxJ/eqVyKuuox/nP88HoHYG2W4hoTTvM559wm4E9k//v6LnC8mb2DPzV4OPA7sv19NaUgU4g3/Lrpy/EFospi36AsHr8d0L7K43/hz4PewNeLqdeHx8fw9SLc3DTHU8LXC84NigP/F9kKfCGwU3jcOQNx9ajy+Of4c7YAg/h60W85vqCb9p9z+Oz3Ar+ttj3qd1ZHXFG/M6Ar0DE83gl4GTgW+BtfL+yeGx6fx9cLuw/WFW8G4upR5fv8LfCbGP/2Q9sj2VEIz+r3lbZfLoV0w4+GeBN/fvWKLB979/ADXQAsrjw+/lzkc8BbwLOV//jCP9RbQqyvA6VpjOUB/GmLLfjznpMaEwfwI3yxrQI4M0Nx3ReOuxAo4+u/EK8IcS0Dxmbq5wwcjD/1tBCYH25Hx/7O6ogr6ncGDAWS4fiLgF9V+T8wN3z2vwFtwva24XlFeH33+uJNc1zPh+9rEXA/O0ZYZe3ffpV2R7IjaWT1+9I0IiIikjLVNEREJGVKGiIikjIlDRERSZmShoiIpExJQ0REUqakIZJmZnZFmB11YZgNdYSZXWhmO8eOTaSpNORWJI3M7EDg/4CRzrlNZtYFfyHcv/Dj99dEDVCkidTTEEmvHsAa56eaICSJ8UBP4AUzewHAzI4ys1fNLGFmfwvzQlWupXK9+fVU5ppZ/1gfRKQmShoi6fU00MfM3jSzW83sUOfczcAHwGHOucNC7+NK4AjnJ6Ysx6+RUGm9c24I8Af8dBUiOaNl/buISKqcc1+Y2X7AIcBhwAz75gp3B+AXwnnFL29Aa+DVKq8/UOX+psxGLNIwShoiaeac2wa8CLxoZq8DE6vtYvg1Gk6prYlaHotEp9NTImlkZnuZ2YAqm4YD7wKf45daBZgNfLeyXmFm7cxszyrv+UGV+6o9EJHo1NMQSa9dgN+bWUdgK36G0cnAKcAsM/sg1DXOAB6osvrblfjZYwE6mdlCYFN4n0jO0JBbkRwSFtjR0FzJWTo9JSIiKVNPQ0REUqaehoiIpExJQ0REUqakISIiKVPSEBGRlClpiIhIyv4/NrfUaA04jWEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "# compute lr \n",
    "test_schedule = CosineSchedule(train_steps=4000, warmup_steps=500)\n",
    "lrs = []\n",
    "for step_num in range(4000):\n",
    "    lrs.append(test_schedule(float(step_num)).numpy())\n",
    "\n",
    "# draw\n",
    "plt.plot(lrs, 'r-', label='learning_rate')\n",
    "plt.xlabel('Step')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00db4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 4,551,936\n",
      "Trainable params: 4,551,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성\n",
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cb63722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "647a9242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/aiffel/aiffel/assets'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# /aiffel/data/는 읽기 전용 -> 경로 변경\n",
    "model_path = os.getenv('HOME') +'/aiffel/assets'\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c34afce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 257s 127ms/step - loss: 17.0450 - nsp_loss: 0.6147 - mlm_loss: 16.4304 - nsp_acc: 0.6343 - mlm_lm_acc: 0.1316\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.13159, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 16.7333 - nsp_loss: 0.6123 - mlm_loss: 16.1210 - nsp_acc: 0.6335 - mlm_lm_acc: 0.1375\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.13159 to 0.13753, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 16.3028 - nsp_loss: 0.6068 - mlm_loss: 15.6959 - nsp_acc: 0.6415 - mlm_lm_acc: 0.1449\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.13753 to 0.14488, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.9661 - nsp_loss: 0.6019 - mlm_loss: 15.3642 - nsp_acc: 0.6521 - mlm_lm_acc: 0.1505\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.14488 to 0.15049, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.6917 - nsp_loss: 0.5960 - mlm_loss: 15.0958 - nsp_acc: 0.6639 - mlm_lm_acc: 0.1554\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.15049 to 0.15538, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.4615 - nsp_loss: 0.5887 - mlm_loss: 14.8728 - nsp_acc: 0.6787 - mlm_lm_acc: 0.1592\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.15538 to 0.15923, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.2655 - nsp_loss: 0.5789 - mlm_loss: 14.6866 - nsp_acc: 0.6945 - mlm_lm_acc: 0.1628\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.15923 to 0.16277, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.1144 - nsp_loss: 0.5695 - mlm_loss: 14.5449 - nsp_acc: 0.7088 - mlm_lm_acc: 0.1654\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.16277 to 0.16538, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 15.0106 - nsp_loss: 0.5606 - mlm_loss: 14.4501 - nsp_acc: 0.7217 - mlm_lm_acc: 0.1673\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.16538 to 0.16727, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 254s 127ms/step - loss: 14.9596 - nsp_loss: 0.5559 - mlm_loss: 14.4037 - nsp_acc: 0.7287 - mlm_lm_acc: 0.1681\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.16727 to 0.16810, saving model to /aiffel/aiffel/assets/bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_path}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(\n",
    "    pre_train_inputs,  \n",
    "    pre_train_labels,  \n",
    "    epochs=epochs,  \n",
    "    batch_size=batch_size,  \n",
    "    callbacks=[save_weights]  #weight저장\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534f9d0",
   "metadata": {},
   "source": [
    "####  10 epochs 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2cd87e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAEGCAYAAABsNP3OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3x0lEQVR4nO3deXhV1b3/8fc3c8KQQBIGmRIBARkKGhQH6oC1qCgOvaLV/kSrVCrOs9bhejvd1sdaW68Wx6pc52K5Sh2qta11KIioIIoIESIgGUgYAiHD9/fHTk4GEsDk5Jwk5/N6nv3k7L32Oee7o139uLL22ubuiIiIiIjEgrhoFyAiIiIiEikKvyIiIiISMxR+RURERCRmKPyKiIiISMxQ+BURERGRmJEQyS/LysrynJycSH6liEhYvP/++0Xunh3tOiJJfbaIdGYt9dsRDb85OTksXrw4kl8pIhIWZvZltGuINPXZItKZtdRva9qDiIiIiMQMhV8RERERiRkKvyIiIiISMxR+RURERCRmKPyKiIiISMxQ+BURERGRmKHwKyIiIiIxI6Lr/LZKURE8+STk5kJODgwZAj16RLsqEREREQkDd6e8spyi8iKKdxRTXF7c6PWU/adw5OAjw/Z9HT/8LlsGl13W+FhmJjzxBEydCl98AX/5SxCM67bu3aNQqIiIiEhsc3fKKsqC8FpeTPGO4kavi8uLKdqxe1tFdUWLn5mamBpj4feoo2DjRsjPb7wNHhy0v/02XHpp4/dkZcFrr8H48fDBB8E5dcF4yBCFYxEREZF9UFVTxdqytazfur7ZMNt0tLZkRwnVXt3sZ8VZHJmpmWSmZZKZmkluRi55/fPITMskKy0r1Nbwde/U3iTEhTeu7vXTzOxhYBqwyd3HNDh+KXAJUA285O7XhbWy+i+Cvn2D7dBDd28/91w4/vggEK9ZUx+O99svaH/lFbjxxsbvycqCjz+Gfv3gb3+DTz5pPHLcrVu7XIqIiIhIR1NRVcGa0jWsKlnFqpJVfFHyBas2B6/zS/Opqqna7T1J8UlkptYG1bRMDsw+sMUAW/c6PSWdOIv+7Wb7EqUfBX4PPFZ3wMyOAaYD33L3CjPr0z7l7YO9hePrroOZM3cfOc7KCtqfew7+538av6dfPygogPh4ePVV2LIFxoyBYcMgoeMPlouIiIg0tG3XNr4o+YIvNn9RH3JrX68rW4fjoXN7JvdkWO9hTOg3gf848D8Y1nsYA3oMICstKxR2uyV2w8yieEWtt9ck5+7/MLOcJodnA79094racza1Q23hERcXhNl+/WDSpN3bf/c7uOWWxqPGpaVB8AX4zW/g5ZeD18nJMGoUTJ4M99wTHCspgV69ghAuIiIiEiUlO0qCUdsGwbbu9cZtGxudm52WzdDeQ/n2kG8zrNcwhvYeyrDewxjWexiZqZmdNtjui9YOYx4ATDaznwE7gWvcfVH4yoqghuH4sMN2b//Tn2DFiuDGu7qtsLC+/eijg8A8enQwOjxmTBCymxuFFhEREWkld+fr7V/XT00oWcWqzfWvN+/c3Oj8AT0GMKz3ME4cdmIo2A7tPZShvYaSnpIepauIvtaG3wSgNzAJmAg8Y2b7u7s3PdHMZgGzAAbX3aTWmaSmwkEHBVtzrrgiuKlu2TKYPx8efBDOOScIv+5wyinBPOK6YDx6NGRkRPACREREpDMpryxnZfFKPi36lM+KPuPT4uDnyuKVbK/cHjovzuIYkj6EYb2HcdaYsxjaq370NrdXLmmJaVG8io6rteG3APhTbdj9t5nVAFlAYdMT3X0uMBcgLy9vt3Dc6V1wQf1rd9i0CXbuDPa3bQvWKX7zzeB1nf/6L/jJT2DHDnj22SAUjxoVBG0RkVYws6nAb4F44EF3/2WT9t8Ax9TupgF93D0jokWKSIi789XWr4JwW/QpnxXX/1xbtjZ0nmHkZOQwImsEkwdPZnjm8FDIHZIxhKT4pCheRefU2vD7AkEn+jczOwBIAorCVVSnVXfzXZ0ePeCdd6CmBtatq582ccQRQfvy5XDeecHruDgYOjQIwtddF0ydKC8PgnTv3pG/FhHpNMwsHrgX+A7B4MQiM1vg7p/UnePuVzY4/1JgQsQLFYlB5ZXlfF78eaNw+2nRp6wsXsm2XfUDY92TujMyaySTB09mZNZIRmSOYGTWSIb1HkZqogbHwmlfljp7EjgayDKzAuA24GHgYTNbBuwCzmtuyoPUiosL1hceMgROOqn++Pjx8Omn9aH444+Dn3Ujx6++CqedFkyT2H//YBs6FC65BAYNCs5LSNAKFCJyCLDK3VcDmNlTBCvyfNLC+WcT9OUiEgbuzoZtG+qnKTQIuWvL1oZWUjCMwemDGZk1kiMHHRmE3Kwg5Pbv3r9L32TWkezLag9nt9B0bphriT0JCTBiRLCdccbu7WPGwF13BU+xW706CMcLFgRLtwE88ABcdVUQqhuG4x/9CHr2hOrq+lUrRKQrGwCsa7BfADR7162ZDQFygTdaaO/c92mItKOKqor6ubgNRnI/K/qMrbu2hs7rltiNEVkjOGLwEVyQeUFoJHd45nDNw+0ANGTYkQ0bBlde2fhYdXX9smoTJwZTJFavDrbnnoPiYpg9O2i/6SZ46KEgEDcMxzNnBqPRIhKLzgKec2/+EUxd/j4NkX1QWV3J5yWfs3zTcpZtWsbywuUsL1zO58WfN3p62eD0wYzIHMHM8TND0xRGZI1gQI8BGsXtwBR+O5uGI7mTJu2+dvGWLfWPbz7iCCgrC4LxokVBOO7Ro/4mvfPPD+YkNwzGI0fCCSdE5lpEJFy+AgY12B9Ye6w5ZxE8nVMk5lXXVPPF5i92C7mfFX1GZU0lEExVGNZ7GKP7jOaMUWcwOns0o7JHMbz3cLol6YmwnZHCb1fTs2f961NOCbY6VVXw9df1+xMnBqtQfPEF/OtfQXAeN64+/B53XLCG8cCB9duECTBjRtBeXBzMR9bUCpFoWwQMN7NcgtB7FvD9pieZ2UigF/BOZMsTia4aryG/NH+3kLuicAUV1RWh83IzchndZzQnDT+JMX3GMDp7NCOzRuqGsy5G4TeWJCTAgAH1+z/+cbBBsExbSQlsbrBA9pQp8NFHwaOe3347+Hn88fXhd8IE2LAB9tuvPhx/97v1I8uLFgWrX/TvD4mJkblGkRjk7lVmNgd4hWCps4fdfbmZ3QEsdvcFtaeeBTylG5Slq3J31m1Zt1vI/aTwE8ory0PnDeo5iNF9RjMld0oo5I7KHkX3pO5RrF4iReFXAmaQmRlsdW68sfE5NTXB2sR1br4ZvvwSvvoqCMZLl9aH6+rq4Il5dXOU+/ULwvEFF8DFFwfHn3oqOH/gwOCn1jkWaTV3XwgsbHLs1ib7t0eyJpH2Ure6wrJNy1i+aXko5C7ftLzRjWf9u/dndJ/RXHTQRaGQe2D2gTH9dDNR+JVvIi4OujWY3/SjH7V8rju8+GIQiuu2r76qnyKxcSOc22TBkMxM+MUv4KKLgoeF/OIXwchxv37Bz759g5sAG07tEBGRLqu6ppovy75kReEKVhStqP9ZtILSnaWh87LTshndZzT/71v/LxRyR/cZTe9UrZMvu1P4lfaRkABTp7bc3rdvsMZxw3BcUBDcdAewfn2wlNv27Y3f99hj8IMfBFMqzjuvPhTXBeQZM4Kb97ZuhdJS6NMHkpPb7TJFRKTtKqoq+Lzk80bhdkXhCj4r/oydVTtD5/Xp1odRWaM4a/RZjO4zOhRy+3TrE8XqpbNR+JXoaLjGcXPGjw9uxtu2LbhJr27LywvaExODR0J//TW8/34wkrxtW7D6xf77w8KFcNZZwbkZGfUB+f77gxUtli2Dd9+tD899+0JWFqSl1S8lJyIiYbWlYgufFn26W8hdvXl1oyXEcjJyGJU1iim5UxiVPYpRWaMYlT1KI7kSFgq/0rF17x5sdSPCdcaPh+efb3ysvLz+xrqJE+EPf2gcnDdurB8FfvVVuPrq3b8vPz94aMgjj8DjjweBuG4udFZWMF85JSUYmd6xIzienq7ALCJSy93ZtH3TbtMUVhSu4Kut9SvwJcYlMjxzOOP6jmPG6BmhkDsia4QeBCHtSuFXuo60Bp3l/vvDrFktn3vJJcFT9RqG4+LiYJpEnV27gtUuiouDlTBqaupXx/jFL+D3vw9eJyRA797B6PGHHwZB+LHHYPnyxuG5b9/6dZndFZhFpFOr8Rq+LP2y2ZC7eWf9ykHdErsxKnsUx+YeGxrBHZU1iv177U9ivFYCkshT+JXYlJwcjPAOGdJ8+/nnB1udmppgDnFSUrB/wQXBFIzi4mArKgrCcl2g/cc/gpHjXbvqP2PAgGBeMwTrL//rX0Eo7t07GD0eNQp++9ug/Y9/DAJ3enr91r8/jB4dtFdUBLUoQItIO6kbwV1Tuob80nzWbF5T/7p0DWvL1rKrur6Py0rL4sDsAzlz9JmNQu7AngP1tDPpUBR+RfZFXFwQUutMmBBsLXnwwfob9oqKgoBcUb+QOtOnB8G7Ljxv2RKsmVznnntgyZLGnzl5chCqIZj2sWpVfTDu2TN4KMmvfx2033prsJxcXVt6OhxwABx8cNBeUBBMJ+nRQw8pEYlR7k7JjpJQmF2zuT7Y5pfmk1+az46qHY3ek5WWRW5GLhP6TeD0kacztPfQUNDNSsuK0pWIfDMKvyLtxax+znJOTuO2Cy/c83vfey9YsaKsLAjGZWXBXOM6l14aBNiysvqt4bSPJ56AtWuDAFznvPPg0UeD10OH1o9KJyUF77344mA6R1UVHHlkcCwtLVh/OS0tCOynnx7Mdb777sZtaWnB0wGHDQs+9/PP64/XnZeg7kYk0sp2ljUKtGs2ryG/LD8UdBuuiQuQkZJBTkYOI7NGMnXYVHIzcsnJyCG3V/BTD4GQrkD/byTSESUkQK9ewdacurnHLVm9OphXXF5eH57rHiLiDv/zP8GxbduCc3bsgIMOCtorK4MVMsrLg5sEy8uDbcyYoL20FG66affv/NWv4Nprgwef1J3b0H33BQF7+fIgSCclBdeZmBhsd9wRPEHw44+DB6wkJjZuv/LKYMR7+XJ46KH643Xn/eAHMHhwELxff71xe2Ji8MTCln6fIp3U1oqtrC1b2zjgNhjFbTj3FoL5t3VB9uico3cLtxkpGdG5EJEIUvgV6arMgoeSdOsWzBduePyHP2z5famp8PLLLbf36xeE5R076oNxeXlwQx8EP59+uv543XkTJwbtKSlw6KHBCHFVVRC2Kyvr51Pv3BlMAamsbNx+3nlB+5dfBlNK6o7X1ATHv/3tIPy++y7Mnr173UuWKPxKp1JRVUHBlgLWbVnHurJ1rC1bG7yu3V+3ZV2jBz0ApCSkkJORQ05GDpMGTgqCbYOAm5maqfm3EvMsko94z8vL88WLF0fs+0QkBtTUBCE5Pj7Ydu6EzZvrw3HdNmxYmx6hbWbvu3teGCvv8NRnt5/qmmo2bNsQBNqyxoG2LuRu2r5pt/dlpmYyKH0Qg3rWbumDGJw+OBRw+3bvS5zFReGKRDqelvrtvY78mtnDwDRgk7uPadJ2NXAnkO3uReEqVkRkn8XF1Y8aQzCy3HCkWyTC3J3C8sIWQ+26snWs37q+0UMdALondWdw+mAG9RzEhH4T6kNubcAd2HOg1r8VCYN9mfbwKPB74LGGB81sEHA8sDb8ZYmIiHQsFVUVFJYXsmn7pt22r7d/HQq5BVsKGj2SFyA5PpmBPQcyKH0QR+ccHQq5DQNuenK6piSIRMBew6+7/8PMcppp+g1wHfDncBclIiLS3mq8hpIdJc2G2ea2soqyZj8nOT6Zvt37MrDnQA7ufzCnjjg1NFpbF2yz07IVbEU6iFbd8GZm04Gv3P1D/Y9ZRETqfLjxQ8oqyoizOOItnjiLa7TFxzU+1ppzmrYbFgqW23dt321EtqUwW1RetNvUA4A4iyMrLYs+3frQp1sfDt7vYPqk9QntN926J3VXsBXpRL5x+DWzNOAmgikP+3L+LGAWwODBg7/p14mISCdyzWvX8NfVf43499aF4ObCLECPpB6hsLp/r/2ZNHASfbr1oW+3vruF2d6pvYmP08NfRLqq1oz8DgVygbpR34HAEjM7xN03Nj3Z3ecCcyG4c7gNtYqISAf36+/8mpIdJVTXVFPjNY22am98rD3OSU9J3y3MZqdlk5rY+pU+RKRr+cbh190/BvrU7ZtZPpCn1R5ERGR8v/HRLkFEZI/2uhigmT0JvAOMMLMCM9vD6vgiIiIiIh3Xvqz2cPZe2nPCVo2IiIiISDvSY2BEREREJGYo/IqIiIhIzFD4FREREZGYofArIiIiIjFD4VdEpAsws6lm9pmZrTKzG1o450wz+8TMlpvZ/0a6RhGRjqBVjzcWEZGOw8zigXuB7wAFwCIzW+DunzQ4ZzhwI3CEu282sz7Nf5qISNemkV8Rkc7vEGCVu692913AU8D0JudcBNzr7psB3H1ThGsUEekQFH5FRDq/AcC6BvsFtccaOgA4wMz+ZWbvmtnU5j7IzGaZ2WIzW1xYWNhO5YqIRI/Cr4hIbEgAhgNHA2cDD5hZRtOT3H2uu+e5e152dnZkKxQRiQCFXxGRzu8rYFCD/YG1xxoqABa4e6W7rwFWEoRhEZGYovArItL5LQKGm1mumSUBZwELmpzzAsGoL2aWRTANYnUEaxQR6RAUfkVEOjl3rwLmAK8AK4Bn3H25md1hZqfUnvYKUGxmnwB/A6519+LoVCwiEj1a6kxEpAtw94XAwibHbm3w2oGrajcRkZilkV8RERERiRkKvyIiIiISMxR+RURERCRm7DX8mtnDZrbJzJY1OPZrM/vUzD4ys/nNrRUpIiIiItLR7MvI76NA0ycBvQaMcfdxBGtF3hjmukREREREwm6v4dfd/wGUNDn2au3SOgDvEiyoLiIiIiLSoYVjzu8FwF9aatRz4kVERESko2hT+DWzm4EqYF5L5+g58SIiIiLSUbT6IRdmNhOYBkypXTxdRERERKRDa1X4NbOpwHXAUe5eHt6SRERERETax74sdfYk8A4wwswKzOyHwO+BHsBrZrbUzO5v5zpFRERERNpsryO/7n52M4cfaodaRERERETalZ7wJiIiIiIxQ+FXRERERGKGwq+IiIiIxAyFXxERERGJGQq/IiIiIhIzFH5FREREJGYo/IqIiIhIzFD4FREREZGYofArIiIiIjFD4VdEREREYobCr4iIiIjEDIVfEREREYkZCr8iIl2AmU01s8/MbJWZ3dBM+0wzKzSzpbXbhdGoU0Qk2hKiXYCIiLSNmcUD9wLfAQqARWa2wN0/aXLq0+4+J+IFioh0IBr5FRHp/A4BVrn7anffBTwFTI9yTSIiHZLCr4hI5zcAWNdgv6D2WFNnmNlHZvacmQ1q7oPMbJaZLTazxYWFhe1Rq4hIVO01/JrZw2a2ycyWNTjW28xeM7PPa3/2at8yRUSkjf4PyHH3ccBrwB+bO8nd57p7nrvnZWdnR7RAEZFI2JeR30eBqU2O3QC87u7Dgddr90VEJDq+AhqO5A6sPRbi7sXuXlG7+yBwcIRqExHpUPYaft39H0BJk8PTqR81+CNwanjLEhGRb2ARMNzMcs0sCTgLWNDwBDPr32D3FGBFBOsTEekwWrvaQ19331D7eiPQt6UTzWwWMAtg8ODBrfw6ERFpibtXmdkc4BUgHnjY3Zeb2R3AYndfAFxmZqcAVQQDGjOjVrCISBS1eakzd3cz8z20zwXmAuTl5bV4noiItJ67LwQWNjl2a4PXNwI3RrouEZGOprXh92sz6+/uG2r/lLYpnEWJSOtUVlZSUFDAzp07o11Kp5WSksLAgQNJTEyMdikiEiPUd7fNN+23Wxt+FwDnAb+s/fnnVn6OiIRRQUEBPXr0ICcnBzOLdjmdjrtTXFxMQUEBubm50S5HRGKE+u7Wa02/vS9LnT0JvAOMMLMCM/shQej9jpl9DhxXuy8iUbZz504yMzPVebaSmZGZmanRFxGJKPXdrdeafnuvI7/ufnYLTVP2+VtEJGLUebaNfn8iEg3qe1rvm/7u9IQ3EREREYkZCr8i0ink5+czZsyYaJchIiKdnMKviIiIiMSMNq/zKyId0xVXwNKl4f3M8ePh7rv3fE5+fj4nnHACRx55JG+//TYDBgzgz3/+Mw888AD3338/CQkJHHjggTz11FPcfvvtfPHFF6xatYqioiKuu+46Lrroor3WsXPnTmbPns3ixYtJSEjgrrvu4phjjmH58uWcf/757Nq1i5qaGp5//nn2228/zjzzTAoKCqiuruaWW25hxowZYfl9iIiE2xUvX8HSjUvD+pnj+43n7ql37/Gc9uq7t23bxvTp09m8eTOVlZX89Kc/Zfr06QA89thj3HnnnZgZ48aN4/HHH+frr7/m4osvZvXq1QDcd999HH744WH9fSj8ikjYff755zz55JM88MADnHnmmTz//PP88pe/ZM2aNSQnJ1NaWho696OPPuLdd99l+/btTJgwgZNOOon99ttvj59/7733YmZ8/PHHfPrppxx//PGsXLmS+++/n8svv5xzzjmHXbt2UV1dzcKFC9lvv/146aWXACgrK2vPSxcR6bTao+9OSUlh/vz59OzZk6KiIiZNmsQpp5zCJ598wk9/+lPefvttsrKyKCkpAeCyyy7jqKOOYv78+VRXV7Nt27awX6fCr0gXtbcR2vaUm5vL+PHjATj44IPJz89n3LhxnHPOOZx66qmceuqpoXOnT59OamoqqampHHPMMfz73/9u1N6ct956i0svvRSAkSNHMmTIEFauXMlhhx3Gz372MwoKCjj99NMZPnw4Y8eO5eqrr+b6669n2rRpTJ48uZ2uWkSk7fY2Qtue2qPvdnduuukm/vGPfxAXF8dXX33F119/zRtvvMF//Md/kJWVBUDv3r0BeOONN3jssccAiI+PJz09PezXqTm/IhJ2ycnJodfx8fFUVVXx0ksvcckll7BkyRImTpxIVVUVsPsSNW1Z7uf73/8+CxYsIDU1lRNPPJE33niDAw44gCVLljB27Fh+8pOfcMcdd7T680VEurL26LvnzZtHYWEh77//PkuXLqVv375RX0td4VdE2l1NTQ3r1q3jmGOO4b//+78pKysL/Snrz3/+Mzt37qS4uJg333yTiRMn7vXzJk+ezLx58wBYuXIla9euZcSIEaxevZr999+fyy67jOnTp/PRRx+xfv160tLSOPfcc7n22mtZsmRJu16riEhXEY6+u6ysjD59+pCYmMjf/vY3vvzySwCOPfZYnn32WYqLiwFC0x6mTJnCfffdB0B1dXW7TFXTtAcRaXfV1dWce+65lJWV4e5cdtllZGRkADBu3DiOOeYYioqKuOWWW/Y63xfgxz/+MbNnz2bs2LEkJCTw6KOPkpyczDPPPMPjjz9OYmIi/fr146abbmLRokVce+21xMXFkZiYGOpURURkz8LRd59zzjmcfPLJjB07lry8PEaOHAnA6NGjufnmmznqqKOIj49nwoQJPProo/z2t79l1qxZPPTQQ8THx3Pfffdx2GGHhfW6zN3D+oF7kpeX54sXL47Y94nEmhUrVjBq1Khol7HPbr/9drp3784111wT7VIaae73aGbvu3telEqKCvXZIpGhvrvtvkm/rWkPIiIiIhIzNO1BRKLm9ttv3+3Yxx9/zA9+8INGx5KTk3nvvfciVJWIiOxJZ++7FX5FpEMZO3YsS8P9dA4REWlXnanv1rQHEREREYkZCr8iIiIiEjMUfkVEREQkZrQp/JrZlWa23MyWmdmTZpYSrsJERERERMKt1eHXzAYAlwF57j4GiAfOCldhItJ1Pfroo8yZM6fNn5OTk0NRUVEYKhIRkb0JV98dbW2d9pAApJpZApAGrG97SSIiIiIi7aPVS525+1dmdiewFtgBvOrurzY9z8xmAbMABg8e3NqvE5HWOPro3Y+deSb8+MdQXg4nnrh7+8yZwVZUBN/7XuO2N9/c61fm5+czdepUJk2axNtvv83EiRM5//zzue2229i0aRPz5s1r8nUzSU1N5YMPPmDTpk08/PDDPPbYY7zzzjsceuihPProo/t0qXfddRcPP/wwABdeeCFXXHEF27dv58wzz6SgoIDq6mpuueUWZsyYwQ033MCCBQtISEjg+OOP584779yn7xARiYSjm+m7zzzzTH784x9TXl7Oic303TNnzmTmzJkUFRXxvSZ995sdrO+ePXs2ixYtYseOHXzve9/jP//zPwFYtGgRl19+Odu3byc5OZnXX3+dtLQ0rr/+el5++WXi4uK46KKLuPTSS/d6PXvS6vBrZr2A6UAuUAo8a2bnuvsTDc9z97nAXAgeldn6UkWks1i1ahXPPvssDz/8MBMnTuR///d/eeutt1iwYAE///nPOfXUUxudv3nzZt555x0WLFjAKaecwr/+9S8efPBBJk6cyNKlSxk/fvwev+/999/nkUce4b333sPdOfTQQznqqKNYvXo1++23Hy+99BIAZWVlFBcXM3/+fD799FPMjNLS0vb5JUSYmU0FfkswBe1Bd/9lC+edATwHTHR3PbtYREIi1Xf/7Gc/o3fv3lRXVzNlyhQ++ugjRo4cyYwZM3j66aeZOHEiW7ZsITU1lblz55Kfn8/SpUtJSEigpKSkzdfZlodcHAescfdCADP7E3A48MQe3yUikbOn/9pPS9tze1bWPo30Nic3N5exY8cCMHr0aKZMmYKZMXbsWPLz83c7/+STTw619+3bt9F78/Pz9xp+33rrLU477TS6desGwOmnn84///lPpk6dytVXX83111/PtGnTmDx5MlVVVaSkpPDDH/6QadOmMW3atFZdY0diZvHAvcB3gAJgkZktcPdPmpzXA7gc6HiPXBKRkD2N1Kalpe2xPSsra59GepsTqb77mWeeYe7cuVRVVbFhwwY++eQTzIz+/fszceJEAHr27AnAX//6Vy6++GISEoLI2rt371ZdW0NtmfO7FphkZmlmZsAUYEWbKxKRTi85OTn0Oi4uLrQfFxdHVVVVi+c3PHdP5++rAw44gCVLljB27Fh+8pOfcMcdd5CQkMC///1vvve97/Hiiy8yderUVn9+B3IIsMrdV7v7LuApgr/MNfVfwH8DOyNZnIh0DpHou9esWcOdd97J66+/zkcffcRJJ53Ezp2R7ZJaHX7d/T2CP50tAT6u/ay5YapLRGSfTZ48mRdeeIHy8nK2b9/O/PnzmTx5MuvXryctLY1zzz2Xa6+9liVLlrBt2zbKyso48cQT+c1vfsOHH34Y7fLDYQCwrsF+Qe2xEDM7CBjk7i/t6YPMbJaZLTazxYWFheGvVERi2pYtW+jWrRvp6el8/fXX/OUvfwFgxIgRbNiwgUWLFgGwdetWqqqq+M53vsMf/vCHUJiO9rQH3P024LY2VyEi0gYHHXQQM2fO5JBDDgGCG94mTJjAK6+8wrXXXktcXByJiYncd999bN26lenTp7Nz507cnbvuuivK1bc/M4sD7gJm7u1c3achIu3pW9/6FhMmTGDkyJEMGjSII444AoCkpCSefvppLr30Unbs2EFqaip//etfufDCC1m5ciXjxo0jMTGRiy66qM3LrZl75Pq2vLw8X7xY91eItJcVK1YwatSoaJfR6TX3ezSz9909L0ol7ZGZHQbc7u7frd2/EcDdf1G7nw58AWyrfUs/oAQ4ZU83vanPFokM9d1t9036bT3eWESk81sEDDezXDNLInjg0IK6Rncvc/csd89x9xzgXfYSfEVEuqo2TXsQEYmEQw89lIqKikbHHn/88dCdxbHO3avMbA7wCsFSZw+7+3IzuwNY7O4L9vwJIiLh11H7boVfkS7G3QkWYOk63nsvcitzRXIqWDi5+0JgYZNjt7Zw7tGRqElE9p367tb7pv22pj2IdCEpKSkUFxd32gAXbe5OcXExKSkp0S5FRGKI+u7Wa02/rZFfkS5k4MCBFBQUoCWqWi8lJYWBAwdGuwwRiSHqu9vmm/bbCr8iXUhiYiK5ubnRLkNERL4B9d2RpWkPIiIiIhIzFH5FREREJGYo/IqIiIhIzFD4FREREZGYofArIiIiIjFD4VdEREREYobCr4iIiIjEDIVfEREREYkZCr8iIiIiEjPaFH7NLMPMnjOzT81shZkdFq7CRERERETCra2PN/4t8LK7f8/MkoC0MNQkIiIiItIuWh1+zSwd+DYwE8DddwG7wlOWiIiIiEj4tWXaQy5QCDxiZh+Y2YNm1q3pSWY2y8wWm9niwsLCNnydiIiIiEjbtCX8JgAHAfe5+wRgO3BD05Pcfa6757l7XnZ2dhu+TkRERESkbdoSfguAAnd/r3b/OYIwLCIiIiLSIbU6/Lr7RmCdmY2oPTQF+CQsVYmIiIiItIO2rvZwKTCvdqWH1cD5bS9JRERERKR9tCn8uvtSIC88pYiIiIiItC894U1EREREYobCr4iIiIjEDIVfEREREYkZCr8iIl2AmU01s8/MbJWZ7bbmupldbGYfm9lSM3vLzA6MRp0iItGm8Csi0smZWTxwL3ACcCBwdjPh9n/dfay7jwd+BdwV2SpFRDoGhV8Rkc7vEGCVu692913AU8D0hie4+5YGu90Aj2B9IiIdRlvX+RURkegbAKxrsF8AHNr0JDO7BLgKSAKObe6DzGwWMAtg8ODBYS9URCTaNPIrIhIj3P1edx8KXA/8pIVz5rp7nrvnZWdnR7ZAEZEIUPgVEen8vgIGNdgfWHusJU8Bp7ZnQSIiHZXCr4hI57cIGG5mubWPmz8LWNDwBDMb3mD3JODzCNYnItJhaM6viEgn5+5VZjYHeAWIBx529+Vmdgew2N0XAHPM7DigEtgMnBe9ikVEokfhV0SkC3D3hcDCJsdubfD68ogXJSLSAWnag4iIiIjEDIVfEREREYkZCr8iIiIiEjMUfkVEREQkZrQ5/JpZvJl9YGYvhqMgEREREZH2Eo6R38uBFWH4HBERERGRdtWm8GtmAwkWS38wPOWIiIiIiLSfto783g1cB9S0dIKZzTKzxWa2uLCwsI1fJyIiIiLSeq0Ov2Y2Ddjk7u/v6Tx3n+vuee6el52d3dqvExERERFps7aM/B4BnGJm+cBTwLFm9kRYqhIRERERaQetDr/ufqO7D3T3HOAs4A13PzdslYmIiIiIhJnW+RURERGRmJEQjg9x9zeBN8PxWSIiIiIi7UUjvyIiIiISMxR+RURERCRmKPyKiIiISMxQ+BURERGRmKHwKyIiIiIxQ+FXRERERGKGwq+IiIiIxAyFXxERERGJGQq/IiIiIhIzFH5FREREJGYo/IqIiIhIzFD4FRHpAsxsqpl9ZmarzOyGZtqvMrNPzOwjM3vdzIZEo04RkWhT+BUR6eTMLB64FzgBOBA428wObHLaB0Ceu48DngN+FdkqRUQ6BoVfEZHO7xBglbuvdvddwFPA9IYnuPvf3L28dvddYGCEaxQR6RAUfkVEOr8BwLoG+wW1x1ryQ+AvzTWY2SwzW2xmiwsLC8NYoohIx6DwKyISQ8zsXCAP+HVz7e4+193z3D0vOzs7ssWJiERAq8OvmQ0ys7/V3kCx3MwuD2dhIiKyz74CBjXYH1h7rBEzOw64GTjF3SsiVJuISIfSlpHfKuBqdz8QmARc0swNFiIi0v4WAcPNLNfMkoCzgAUNTzCzCcAfCILvpijUKCLSIbQ6/Lr7BndfUvt6K7CCPc8xExGRduDuVcAc4BWCvvgZd19uZneY2Sm1p/0a6A48a2ZLzWxBCx8nItKlJYTjQ8wsB5gAvNdM2yxgFsDgwYPD8XUiItKEuy8EFjY5dmuD18dFvCgRkQ6ozTe8mVl34HngCnff0rRdN0+IiIiISEfRpvBrZokEwXeeu/8pPCWJiIiIiLSPtqz2YMBDwAp3vyt8JYmIiIiItI+2jPweAfwAOLb25omlZnZimOoSEREREQm7Vt/w5u5vARbGWkRERESkGTU1NVRWVrJr1y4qKyuprKzE3enXrx8A+fn5bN68udE5ycnJHH744QC88cYbbNiwIfTeyspKMjMzmTFjBgD3338/69ata9Q+dOhQrrzySgCuuOIK1q9fT01NTWibOHEiN998MwAzZsyguLiYmpoaqqurqamp4bjjjuO2224D4Mgjj6S8vLxR+5lnnsltt91GdXU1w4cPb9RWU1PD7NmzufXWW5v+KtosLKs9iIiIiHRl27dvp6ioiPLycioqKti5cycVFRVMmjSJ5ORkli1bxtKlS6moqGi0XXXVVSQlJfHCCy/w2muvNXpvZWUl8+fPx8z4+c9/zrPPPtvovUlJSaxevRqA73//+zz99NONaurfvz/r168HYM6cObz00kuN2ocPH87KlSsBuOOOO/j73//eqP2ggw4Khd8HHniADz/8kMTERBITE0lKSmLy5Mmh8LtixQrWrl1LXFwc8fHxxMXFkZOT0+j3s3PnTuLi4oiLiyMpKYnExMRQe9++famsrAy1x8fH079/fwDi4uI44ogjQp9b93P06NFt/cfWLIVfERER6XSqqqooLy8nOTmZ5ORktmzZwsqVKykvL2+0HXvssey3334sX76cp556ivLycnbs2BFq/9nPfsbw4cN54YUXuO222xq9d8eOHXzwwQeMGjWKuXPnctVVV+1Wx9q1axk0aBDz589vdpTyRz/6EUlJSXzwwQc8/fTToXrrturqahISEujZsyeDBg1q1NatW7fQ58yYMYNx48aFQmViYiI9evQItd90001ceOGFLbY/+uij7Nq1K9SWmJhISkpKqH3x4sUEt3M175VXXtnjP48XX3xxj+3PP/98i21mxuOPP77H94eTuXvEviwvL88XL14cse8TEQkXM3vf3fOiXUckqc+Wtti1axfl5eUkJCTQvXt3KioqWLx4Mdu3b6e8vDz089BDD2XcuHFs3LiRX/7yl43at2/fzlVXXcUJJ5zAkiVLOPnkk0PtlZWVADz33HOcccYZvPrqq3z3u9/drY6//OUvTJ06lfnz53PGGWeQlpbWaHviiSc46KCDeP311/n9739Pampqo/bLL7+c/v37s2zZMhYtWkRKSgopKSkkJyeTkpLC4YcfTkpKCkVFRWzevHm3cJuSkrLHUCntp6V+WyO/IiIiAsD69espKytj69atbNmyha1btzJgwAAOOeQQampquPnmmxu1bd26ldNOO41LLrmEbdu2ccABB4TCaVVVFQC33347t912G8XFxRx55JG7feevfvUrxo0bx7Zt23jkkUdIS0ujW7dudOvWjbS0tFDI7d27NyeccELoeN02ZswYACZMmMCLL77YKLympqYyYEDw8Nnp06dTXV3dYhCdMmUKU6ZMafF3M2bMmNB3NScrK4usrKx9+0VLVCn8ioiIdELuzrZt26ioqAiFrnfeeYeNGzc2Cqj9+/dn5syZAFx44YWsWbOmUftxxx3HH//4RyAIeJs3b270Peeddx6HHHIIcXFx3HvvvSQlJdGjRw969uxJt27dqK6uBiAlJYVp06aFwmtdAK274SorK4tXXnkl1FYXcHv16gXAsGHDKCsra/F6c3JyePDBB1tsz87O5qSTTmqxPS6uzc/1ki5C4VdERCQKdu3aRWlpKeXl5aEbh/75z3+ycuVKysrKKC0tpaysjG7duvHzn/8cgPPPP58333yTsrIyysrKqKmp4eCDD6ZuesqcOXNYsmRJo+85+uijQ+G3qKgoFJZzc3Pp2bMnEydODJ37u9/9jvj4+FC47dmzJ3379g21b9my24NcQxISEpg7d26L7UlJSRx//PHf6Hck0h4UfkVERFqhurqakpISioqKGDlyJGbGe++9x6JFixqF1+3btzNv3jwArrvuOh577DHKysrYuXMnAL169aKkpASAe+65h+eeew4IbgLq0aMHI0eODH1nbm4uVVVVpKenk5GRQXp6OkOGDAm1P/LII9TU1NCzZ89QgE1OTg61v/DCC3u8pnPOOScsvxuRjkzhV0REpFZJSQmrVq2iqKiIoqIiCgsLKSoq4oYbbiA9PZ0HH3yQO++8k6KiIkpKSqi7aby0tJT09HSef/55fv3rXwPBNIC6kFpVVUVCQgIjR47klFNOaRRee/fuHfr+3/zmN9x5551kZGTQo0eP3f5Uv7c1T8eNGxfm34hI16PwKyIiXU5FRQXFxcWh8Pqtb32LrKwsli5dykMPPRQ6XrctXLiQcePG8cwzzzB79uxGn5WQkMDMmTNJT08nMzMz9FlZWVlkZ2eTlZVFUlISADfeeCPXXHMN6enpjUZc61xwwQVccMEFLdY9cODA8P4iRGQ3Cr8iItIh1c2JLS0tJTMzk8zMTAoLC3n++ecpLS1l8+bNofY5c+YwefJk/v73v3PyySezdevWRp/14osvctJJJ1FQUMC8efNCwXXIkCHk5eWRlpYGwNSpU/m///u/UKjNysqiZ8+eoRUCTjvtNE477bQWa667eUtEOq4OH36vuQZqVzkBoOkKJZHab/izuWOtOac157blPW35jra2t/Yzo7Efa1vDfwYi4VRTU8OWLVsoLS0lNTWVvn37snPnTp588slQcK37edppp3H66aezdu1aDjvssNCNYHXuueceLr30UjZu3BgamU1KSqJXr15kZGSE5swOGjSICy64oFF4zcrKCk0HmDZtWujc5uTk5DR6apWIdD0dPvzOmwe19wTQ9Hkckdpv+LO5Yy2dI9LZtDVAtyV4NwzgLbW19mfTY/PmwYQJbftdSfNqamoYPnw4JSUllJWVhebEXnnlldx1111UV1eH/uxvZmRkZJCRkcGhhx4KQEZGBieccELoeF24PeSQQwAYOXIk69evJyMjg9TU1N2+f//99+fuu++OzMWKSKfU4cPvhg3RrqDt9iUof5OfrXlPW76jre2t/cxo7MfaFo7rb+1nNPfvXlv/vd3Xz6z9C7e0g7i4OI499lhSU1Mbhde6kde0tDTWrFlDr169mr2hq2fPnntcyzUxMZH+/fu36zWISNfW4cNvV6A/LYtILHnggQdabDMzTSsQkajS405EREREJGYo/IqIiIhIzGhT+DWzqWb2mZmtMrMbwlWUiIiIiEh7aHX4NbN44F7gBOBA4GwzOzBchYmIiIiIhFtbRn4PAVa5+2p33wU8BUwPT1kiIiIiIuHXlvA7AFjXYL+g9lgjZjbLzBab2eLCwsI2fJ2IiIiISNu0+w1v7j7X3fPcPS87O7u9v05EREREpEVtCb9fAYMa7A+sPSYiIiIi0iGZN3wM0jd5o1kCsBKYQhB6FwHfd/fle3hPIfBlK74uCyhqTZ2dWCxeM8TmdcfiNUPnu+4h7h5Tf75Sn/2NxeJ165pjR2e87mb77VY/4c3dq8xsDvAKEA88vKfgW/ueVv0fh5ktdve81ry3s4rFa4bYvO5YvGaI3evuTNRnfzOxeN265tjRla67TY83dveFwMIw1SIiIiIi0q70hDcRERERiRmdJfzOjXYBURCL1wyxed2xeM0Qu9cdC2L1n20sXreuOXZ0metu9Q1vIiIiIiKdTWcZ+RURERERaTOFXxERERGJGR06/JrZVDP7zMxWmdkN0a4nEsxskJn9zcw+MbPlZnZ5tGuKFDOLN7MPzOzFaNcSKWaWYWbPmdmnZrbCzA6Ldk3tzcyurP13e5mZPWlmKdGuScIn1vpt9dnqs6NdU3vrin12hw2/ZhYP3AucABwInG1mB0a3qoioAq529wOBScAlMXLdAJcDK6JdRIT9FnjZ3UcC36KLX7+ZDQAuA/LcfQzBGuFnRbcqCZcY7bfVZ8cW9dldoM/usOEXOARY5e6r3X0X8BQwPco1tTt33+DuS2pfbyX4H9aA6FbV/sxsIHAS8GC0a4kUM0sHvg08BODuu9y9NKpFRUYCkFr7lMg0YH2U65Hwibl+W322+uyoFhUZXa7P7sjhdwCwrsF+ATHQoTRkZjnABOC9KJcSCXcD1wE1Ua4jknKBQuCR2j8dPmhm3aJdVHty96+AO4G1wAagzN1fjW5VEkYx3W+rz+7y1Gd3kT67I4ffmGZm3YHngSvcfUu062lPZjYN2OTu70e7lghLAA4C7nP3CcB2oEvPkTSzXgQjgbnAfkA3Mzs3ulWJtJ367JigPruL9NkdOfx+BQxqsD+w9liXZ2aJBJ3oPHf/U7TriYAjgFPMLJ/gz6THmtkT0S0pIgqAAnevGyV6jqBj7cqOA9a4e6G7VwJ/Ag6Pck0SPjHZb6vPVp/dhXXJPrsjh99FwHAzyzWzJIIJ1guiXFO7MzMjmE+0wt3vinY9keDuN7r7QHfPIfjn/Ia7d/r/stwbd98IrDOzEbWHpgCfRLGkSFgLTDKztNp/16fQxW8YiTEx12+rz1afHcWSIqFL9tkJ0S6gJe5eZWZzgFcI7i582N2XR7msSDgC+AHwsZktrT12k7svjF5J0o4uBebVBoXVwPlRrqdduft7ZvYcsITgLvkP6EKPzIx1Mdpvq8+OLeqzu0Cfrccbi4iIiEjM6MjTHkREREREwkrhV0RERERihsKviIiIiMQMhV8RERERiRkKvyIiIiISMxR+pcMxs2ozW9pgC9sTdMwsx8yWhevzRERinfps6Ww67Dq/EtN2uPv4aBchIiL7RH22dCoa+ZVOw8zyzexXZvaxmf3bzIbVHs8xszfM7CMze93MBtce72tm883sw9qt7pGM8Wb2gJktN7NXzSw1ahclItJFqc+WjkrhVzqi1CZ/QpvRoK3M3ccCvwfurj32O+CP7j4OmAfcU3v8HuDv7v4tguev1z1pajhwr7uPBkqBM9r1akREujb12dKp6Alv0uGY2TZ3797M8XzgWHdfbWaJwEZ3zzSzIqC/u1fWHt/g7llmVggMdPeKBp+RA7zm7sNr968HEt39pxG4NBGRLkd9tnQ2GvmVzsZbeP1NVDR4XY3mvouItBf12dLhKPxKZzOjwc93al+/DZxV+/oc4J+1r18HZgOYWbyZpUeqSBERAdRnSwek/3qSjijVzJY22H/Z3euWzullZh8RjAScXXvsUuARM7sWKATOrz1+OTDXzH5IMFowG9jQ3sWLiMQY9dnSqWjOr3QatfPH8ty9KNq1iIjInqnPlo5K0x5EREREJGZo5FdEREREYoZGfkVEREQkZij8ioiIiEjMUPgVERERkZih8CsiIiIiMUPhV0RERERixv8HzvAvj5+rozwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training result\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d7ecf",
   "metadata": {},
   "source": [
    "#### What I can take from this project  & Future work \n",
    "loss * 20 처럼 MLM loss를 증가시켜, 더 어려운 task의 학습이 잘 되도록 컨트롤할 수 있다.   \n",
    "np.memmap로 필요한 부분만 ram에 로드해서 메모리 관리하며 처리할 수 있다.  \n",
    "모델 구성 코드를 추후 잘 정리해보며 공부해볼 필요가 있다.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
